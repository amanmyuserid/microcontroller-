{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlyECQNKPppm",
        "outputId": "34064ee0-a225-4768-9625-9918c2f448c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/final_pipe_data.zip /content/"
      ],
      "metadata": {
        "id": "8TqXEThNQCtk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip final_pipe_data.zip"
      ],
      "metadata": {
        "id": "FOfkvKKKQCwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d670383-d6fa-40eb-b3c5-bf114433326f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  final_pipe_data.zip\n",
            "   creating: final_pipe_data/\n",
            "   creating: final_pipe_data/train/\n",
            "   creating: final_pipe_data/train/camera_blocked/\n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-11-59-43-578167.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-11-59-46-938004.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-12-24-00-960970.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-13-16-12-293367.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-06-054966.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-06-990630.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-12-951789.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-14-708083.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-16-674829.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-20-386384.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-40-21-484312.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-41-10-827473.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-41-18-920129.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-41-35-496579.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-41-58-269017.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-42-09-531329.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-44-39-482216.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-44-43-735591.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-44-56-849555.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-45-03-020555.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-45-08-569991.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-48-00-365342.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-48-07-960609.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-48-46-060794.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-50-43-931327.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-50-48-478721.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-51-06-233879.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-51-10-265621.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-51-24-257540.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-54-04-020881.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-54-06-378562.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-54-15-612850.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-59-52-748666.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-00-02-835410.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-00-48-088620.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-03-56-461390.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-39-44-130443_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-27-20-963911_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-14-708083_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-47-45-644484_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-03-56-461390_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-49-51-881660_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-14-03-511650_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-26-34-951883_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-06-054966_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-19-47-164738_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-14-22-558085_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-49-55-879884_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-41-55-049983_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-41-18-920129_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-48-46-060794_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-21-40-234146_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-22-35-943583_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-11-59-43-578167_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-22-30-916626_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-28-43-425110_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-10-15-094815_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-44-38-065968_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-54-15-612850_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-40-21-484312_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-29-15-193548_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-12-41-349477_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-54-04-020881_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-22-51-837186_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-21-33-996851_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-23-07-591952_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-44-43-735591_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-44-06-343443_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-21-13-889598_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-36-28-986907_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-48-07-960609_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-20-47-883513_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-45-08-569991_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-36-29-435697_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-12-951789_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-17-41-844496_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-50-40-633829_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-45-03-020555_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-39-43-999001_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-13-16-12-293367_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-10-05-369660_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-10-12-605276_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-51-10-265621_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-47-36-254585_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-14-18-671801_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-10-21-516087_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-41-10-827473_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-11-37-599098_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-29-25-492693_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-00-48-088620_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-18-32-111396_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-20-34-265957_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-16-674829_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-42-09-531329_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-19-29-127171_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-26-05-539516_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-19-36-518337_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-12-24-00-960970_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-00-02-835410_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-21-38-825105_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-51-24-257540_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-41-57-069182_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-41-35-496579_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-26-43-173798_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-19-30-678976_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-51-06-233879_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-21-08-595234_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-29-27-053801_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-44-56-849555_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-50-22-723956_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-54-06-378562_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-20-58-614448_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-11-40-032266_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-13-45-250246_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-41-58-269017_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-23-02-726538_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-11-59-46-938004_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-59-52-748666_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-50-43-931327_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-20-386384_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-45-26-759370_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-13-53-705333_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-26-44-946006_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-23-33-359231_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-45-24-359894_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-25-37-986214_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-14-00-329208_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-44-39-482216_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-01-56-342886_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-50-48-478721_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-19-27-838194_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-17-30-539496_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-23-24-159653_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-28-06-990630_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-29-23-617754_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-10-48-00-365342_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-17-30-539496.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-17-41-844496.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-18-32-111396.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-21-33-996851.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-21-38-825105.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-21-40-234146.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-22-30-916626.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-22-35-943583.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-22-51-837186.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-23-02-726538.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-23-07-591952.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-23-24-159653.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-23-33-359231.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-26-05-539516.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-26-34-951883.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-26-43-173798.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-26-44-946006.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-27-20-963911.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-29-25-492693.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-29-27-053801.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-45-24-359894.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-13-11-45-26-759370.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-36-28-986907.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-36-29-435697.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-39-43-999001.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-39-44-130443.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-41-55-049983.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-41-57-069182.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-44-06-343443.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-44-38-065968.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-47-36-254585.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-47-45-644484.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-49-51-881660.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-49-55-879884.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-50-22-723956.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-09-50-40-633829.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-01-56-342886.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-10-05-369660.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-10-12-605276.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-10-15-094815.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-10-21-516087.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-11-37-599098.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-11-40-032266.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-12-41-349477.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-13-45-250246.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-13-53-705333.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-14-00-329208.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-14-03-511650.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-14-18-671801.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-14-22-558085.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-19-27-838194.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-19-29-127171.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-19-30-678976.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-19-36-518337.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-19-47-164738.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-20-34-265957.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-20-47-883513.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-20-58-614448.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-21-08-595234.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-21-13-889598.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-25-37-986214.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-28-43-425110.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-29-15-193548.jpg  \n",
            "  inflating: final_pipe_data/train/camera_blocked/2023-03-10-10-29-23-617754.jpg  \n",
            "   creating: final_pipe_data/train/nothing/\n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-10-21-18-077647.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-57-32-091807.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-57-33-471800.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-57-44-426789.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-57-46-641573.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-59-26-870791.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-59-34-814856.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-59-38-841442.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-00-02-011964.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-00-18-336910.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-00-45-979168.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-21-38-197372.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-21-45-800569.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-21-51-827398.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-22-51-575187.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-23-04-187360.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-23-09-583983.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-23-15-010198.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-23-23-638412.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-24-51-781467.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-24-59-767705.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-25-01-708524.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-25-43-763255.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-30-38-823784.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-32-43-846372.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-32-58-603022.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-33-07-826003.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-33-35-461982.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-33-39-410155.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-33-47-273822.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-33-58-830837.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-34-31-110123.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-34-55-639710.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-35-16-167247.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-36-35-268437.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-12-03-949171.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-13-53-433238.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-14-11-632705.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-15-52-631026.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-16-26-797773.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-18-01-084765.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-18-12-812706.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-18-32-633490.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-21-57-307924.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-10-43-51-711440.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-10-47-12-800739.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-10-47-18-039976.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-10-47-43-854918.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-10-49-35-874263.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-00-21-395334.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-08-24-547140.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-23-15-010198_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-21-48-328663_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-21-51-827398_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-14-138313_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-21-10-232195_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-30-38-823784_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-10-47-12-800739_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-21-38-197372_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-23-09-583983_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-16-26-797773_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-23-55-937990_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-57-46-641573_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-39-770514_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-39-27-084898_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-23-04-187360_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-19-27-437502_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-20-10-046435_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-32-43-846372_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-57-44-426789_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-18-58-075652_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-46-909255_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-13-53-433238_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-43-53-942746_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-03-509954_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-24-754585_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-16-30-364769_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-02-595468_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-10-47-18-039976_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-14-568468_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-19-38-074957_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-22-27-343778_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-17-14-709348_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-25-06-488647_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-00-21-395334_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-12-322325_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-42-07-507367_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-18-32-633490_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-21-57-403577_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-39-13-631668_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-17-114280_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-36-35-268437_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-22-18-320721_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-41-524055_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-00-317432_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-10-21-18-077647_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-24-23-245422_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-21-57-307924_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-13-14-11-632705_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-25-01-708524_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-38-651565_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-18-43-177896_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-57-32-091807_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-12-23-23-638412_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-18-28-240124_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-17-22-961286_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-23-45-866811_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-18-20-677337_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-17-57-460556_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-59-34-814856_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-42-35-466724_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-24-29-424683_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-50-013949_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-39-43-774733_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-21-745706_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-42-14-027014_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-16-13-316543_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-19-18-090755_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-11-57-33-471800_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-16-13-316543.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-16-30-364769.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-16-37-322493.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-16-53-950926.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-16-58-981056.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-17-14-709348.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-17-22-961286.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-17-57-460556.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-18-20-677337.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-18-28-240124.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-18-43-177896.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-18-58-075652.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-19-18-090755.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-19-27-152303.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-19-27-437502.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-19-38-074957.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-19-52-995557.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-20-10-046435.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-20-44-844720.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-21-02-293734.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-21-10-232195.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-21-48-328663.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-21-51-949457.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-21-57-403577.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-22-02-421676.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-22-18-320721.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-22-27-343778.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-23-45-866811.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-23-47-119432.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-23-55-937990.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-24-23-245422.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-24-29-424683.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-25-06-488647.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-25-59-391369.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-01-150073.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-02-595468.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-03-509954.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-14-138313.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-15-264568.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-18-677508.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-21-745706.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-24-754585.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-36-672461.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-38-651565.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-41-524055.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-26-54-007183.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-10-573759.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-12-322325.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-14-568468.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-17-114280.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-34-335812.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-36-087435.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-39-770514.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-27-46-909255.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-28-14-156719.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-28-35-634774.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-29-00-574042.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-39-13-631668.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-39-27-084898.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-39-43-774733.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-42-07-507367.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-42-14-027014.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-42-23-555911.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-42-35-466724.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-42-51-654007.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-43-53-942746.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-00-317432.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-04-869658.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-06-606745.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-09-549092.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-12-360669.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-13-535808.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-16-751157.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-18-768975.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-49-577253.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-50-013949.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-44-55-334348.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-45-56-981818.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-13-11-45-59-319873.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-09-31-12-091058.jpg  \n",
            "  inflating: final_pipe_data/train/nothing/2023-03-10-09-36-22-526727.jpg  \n",
            "   creating: final_pipe_data/train/pipe_close/\n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-27-19-051852.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-27-37-954929.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-29-47-594335.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-29-53-447571.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-29-59-127973.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-30-08-262938.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-30-15-145689.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-30-29-172751.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-30-33-201720.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-30-37-105721.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-42-26-212667.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-42-29-279481.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-42-32-506087.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-42-38-463993.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-42-45-520516.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-42-47-298323.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-42-52-058298.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-43-13-670355.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-43-21-065529.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-43-25-244381.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-43-27-956745.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-43-31-346566.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-43-33-650898.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-43-47-026135.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-43-59-234465.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-44-10-498497.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-44-17-271798.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-45-22-961731.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-45-28-740425.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-45-31-121599.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-45-37-139617.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-45-40-003003.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-45-57-328185.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-46-01-625194.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-46-20-557817.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-46-24-789599.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-46-32-137593.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-46-34-986672.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-46-42-275080.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-47-20-302395.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-47-29-175467.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-47-33-860763.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-47-37-784246.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-47-39-630698.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-47-49-455871.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-49-13-436662.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-49-56-934156.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-50-00-524183.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-53-02-311857.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-53-09-019064.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-53-32-772066.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-53-40-269103.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-55-30-729007.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-55-42-870064.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-55-49-329973.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-55-58-403187.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-56-06-658528.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-59-15-394685.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-59-23-407147.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-59-26-649152.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-59-29-232458.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-59-31-953431.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-00-10-553220.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-01-41-374682.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-02-03-992327.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-02-43-019425.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-02-46-586061.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-02-53-216276.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-02-56-973520.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-03-04-526734.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-06-45-987493.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-06-51-363699.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-06-57-646135.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-07-04-865288.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-29-13-974740.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-29-16-452010.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-29-20-243475.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-45-40-379420.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-45-42-102544.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-45-44-785092.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-45-47-708376.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-45-50-070177.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-45-51-190367.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-45-54-018773.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-36-24-521960.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-36-25-390506.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-36-25-531667.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-36-26-198584.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-36-26-614097.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-39-36-822626.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-39-37-440729.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-39-38-037473.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-39-38-358430.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-39-38-741532.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-39-39-489358.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-41-12-942562.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-29-982859.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-37-044164.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-37-126628.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-37-182575.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-40-801329.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-43-512455.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-44-955920.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-44-27-157955.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-44-31-014792.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-44-32-410889.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-47-03-992138.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-47-05-226077.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-47-08-185242.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-47-11-109601.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-47-12-694120.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-47-14-242906.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-47-16-386481.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-49-34-059629.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-50-48-185289.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-50-50-078904.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-50-54-186056.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-55-38-610396.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-55-43-579224.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-56-44-916202.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-00-38-183800.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-00-41-030165.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-00-44-295173.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-00-48-305397.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-01-00-496051.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-01-03-811278.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-09-26-389679.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-09-31-606105.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-09-35-229596.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-09-39-191472.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-09-46-627613.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-11-51-286081.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-11-53-084996.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-12-00-433022.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-12-16-487479.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-18-57-044161.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-19-00-768340.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-19-04-514985.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-26-37-824306.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-29-34-215286.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-29-38-600879.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-29-42-153939.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-30-20-411635.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-30-41-835934.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-30-43-749018.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-43-47-026135_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-03-04-526734_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-12-16-487479_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-53-09-019064_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-45-31-121599_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-43-512455_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-56-06-658528_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-46-01-625194_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-47-37-784246_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-37-182575_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-29-20-243475_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-53-40-269103_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-09-39-191472_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-44-955920_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-47-49-455871_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-59-15-394685_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-45-40-379420_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-46-34-986672_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-09-35-229596_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-02-46-586061_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-27-19-051852_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-50-48-185289_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-47-08-185242_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-44-31-014792_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-09-46-627613_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-02-43-019425_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-19-00-768340_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-43-13-670355_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-47-16-386481_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-42-47-298323_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-19-04-514985_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-09-26-389679_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-00-41-030165_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-55-49-329973_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-39-38-037473_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-55-42-870064_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-59-29-232458_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-45-51-190367_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-29-982859_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-29-13-974740_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-39-39-489358_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-50-00-524183_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-46-42-275080_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-47-20-302395_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-36-25-390506_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-30-37-105721_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-49-56-934156_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-43-40-801329_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-11-06-45-987493_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-43-27-956745_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-13-10-45-37-139617_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-09-31-606105_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-49-34-059629_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-09-55-38-610396_flip_hor.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_close/2023-03-10-10-26-37-824306_flip_hor.jpg  \n",
            "   creating: final_pipe_data/train/pipe_inside/\n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-27-41-817786.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-27-44-414532.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-27-46-136450.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-27-47-218060.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-27-48-026107.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-27-51-698208.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-27-53-652016.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-27-56-539940.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-27-59-035477.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-28-00-429511.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-28-02-710010.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-28-24-587420.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-28-25-226713.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-28-27-732802.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-30-39-614885.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-30-45-883365.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-31-03-211125.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-31-10-743766.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-31-14-407202.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-31-16-688686.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-31-19-729776.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-31-20-712057.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-36-42-875156.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-37-45-662162.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-37-56-654070.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-38-00-354174.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-38-02-413966.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-38-11-877602.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-42-52-877183.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-42-57-895607.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-44-18-489302.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-44-26-574759.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-48-24-282794.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-48-27-451105.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-48-34-836475.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-48-52-976966.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-49-23-267828.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-50-05-570325.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-50-11-834958.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-50-17-527274.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-50-19-707543.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-50-37-752636.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-50-59-888504.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-51-36-558970.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-52-01-467513.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-52-12-905899.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-52-24-402741.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-52-31-613476.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-52-53-411776.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-52-56-028097.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-53-22-209973.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-53-24-731109.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-53-57-171864.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-53-59-507826.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-54-37-953584.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-54-51-272704.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-59-37-266149.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-59-39-443740.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-59-43-964024.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-59-47-248365.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-10-59-51-266452.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-00-37-762589.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-00-44-551243.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-00-45-730857.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-01-06-270613.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-01-10-048488.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-03-14-269666.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-03-19-736503.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-03-29-336027.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-03-43-406380.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-03-50-175171.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-06-39-203539.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-29-16-954879.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-29-24-515477.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-45-34-805802.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-45-35-788719.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-13-11-45-37-728394.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-36-27-141751.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-36-27-247297.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-36-28-089964.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-36-28-528491.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-36-28-715249.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-39-40-005882.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-39-42-307435.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-39-42-354749.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-41-18-085969.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-41-19-247808.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-41-45-808020.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-41-50-362000.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-41-52-020763.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-41-53-423604.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-43-49-185831.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-43-49-878160.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-44-12-635411.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-44-23-235584.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-44-24-686621.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-44-36-388327.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-44-37-191181.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-47-17-725073.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-47-22-630551.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-47-24-892776.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-47-27-017269.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-47-29-254349.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-47-30-719481.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-47-32-340660.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-47-33-652431.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-49-41-471970.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-49-41-985778.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-50-28-268334.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-50-30-121634.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-50-31-394920.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-50-32-793678.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-50-34-512709.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-50-36-362683.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-50-42-116075.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-50-43-423960.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-50-44-301571.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-50-45-626496.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-50-46-922438.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-55-44-962740.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-55-47-151109.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-55-50-783644.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-55-53-769141.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-55-56-704358.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-55-58-676235.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-56-05-619393.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-56-09-158041.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-56-18-045315.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-56-27-994694.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-56-30-956127.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-56-37-119178.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-09-56-41-182238.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-07-731142.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-15-198146.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-23-924929.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-26-712691.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-32-692238.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-34-251723.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-43-576938.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-44-910713.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-47-645534.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-54-586107.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-57-723696.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-01-59-776372.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-02-02-457966.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-02-04-386354.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-02-14-114090.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-02-18-461664.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-09-48-503394.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-09-51-679999.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-09-53-263275.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-10-01-525363.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-11-41-309333.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-11-45-574581.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-11-47-993278.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-11-49-262015.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-12-20-884233.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-12-26-227109.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-12-27-865951.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-12-29-795939.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-12-46-572033.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-12-50-985611.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-12-54-826715.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-12-57-674947.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-13-05-445191.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-13-21-541349.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-14-35-054203.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-14-42-607552.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-19-05-874648.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-19-13-377169.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-21-29-864814.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-22-30-721217.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-22-32-401563.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-22-33-750501.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-22-45-109134.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-22-51-779883.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-22-57-428869.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-23-21-475580.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-23-43-092262.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-23-45-257479.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-25-45-755455.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-26-48-317830.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-26-52-069312.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-27-09-316603.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-27-36-127915.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-27-40-540021.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-28-04-181977.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-28-10-665765.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-28-20-688145.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-29-30-935226.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-29-52-790967.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-29-55-505043.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-30-02-683224.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-30-07-045794.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-30-12-035901.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-30-15-179010.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-30-22-770188.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-30-37-670819.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-30-46-672118.jpg  \n",
            "  inflating: final_pipe_data/train/pipe_inside/2023-03-10-10-30-50-451693.jpg  \n",
            "   creating: final_pipe_data/test/\n",
            "   creating: final_pipe_data/test/pipe_close/\n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-27-34-279507.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-27-43-444698.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-30-27-069330.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-42-28-106811.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-42-36-892710.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-43-09-671741.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-43-24-366983.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-44-01-933256.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-44-05-687799.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-45-54-277103.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-46-57-524624.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-49-16-814728.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-13-10-55-36-538339.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-09-36-25-840508.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-09-39-39-376032.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-09-43-28-343031.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-09-43-38-087959.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-09-47-04-189634.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-09-49-35-816776.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-09-55-36-939159.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-09-55-40-947478.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-09-56-43-050455.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-10-09-23-268685.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-10-11-54-851720.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-10-11-57-063798.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_close/2023-03-10-10-26-44-569973.jpg  \n",
            "   creating: final_pipe_data/test/camera_blocked/\n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-13-16-03-784322.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-10-28-04-179225.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-10-40-25-369401.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-10-40-56-693770.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-10-44-37-829056.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-10-48-17-941931.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-10-50-54-778092.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-10-51-33-708633.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-10-52-44-468280.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-11-00-52-982033.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-11-04-15-066666.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-11-18-29-147709.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-11-22-28-864052.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-11-26-27-541382.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-13-11-45-30-285017.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-09-39-43-518728.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-09-39-44-051573.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-09-47-37-754913.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-09-47-41-958482.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-10-10-07-903093.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-10-10-10-481599.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-10-13-42-932768.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-10-13-49-487182.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-10-19-17-829978.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-10-19-34-060728.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-10-20-51-017872.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-10-27-00-100415.jpg  \n",
            "  inflating: final_pipe_data/test/camera_blocked/2023-03-10-10-29-11-364369.jpg  \n",
            "   creating: final_pipe_data/test/pipe_inside/\n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-13-10-27-49-339356.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-13-10-27-55-613234.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-13-10-30-37-341501.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-13-10-31-01-020413.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-13-10-42-21-334836.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-13-10-43-03-535911.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-13-10-48-13-401402.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-13-10-52-05-698961.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-13-10-54-25-546696.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-13-10-59-45-465549.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-09-36-27-613985.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-09-41-21-796427.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-09-43-47-713603.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-09-47-20-247495.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-09-49-47-535096.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-09-55-54-799642.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-01-16-541866.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-01-52-107022.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-02-12-876780.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-09-58-701453.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-13-33-212676.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-22-37-593048.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-23-24-600025.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-26-56-997216.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-27-47-985978.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-28-13-735663.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-29-59-524704.jpg  \n",
            "  inflating: final_pipe_data/test/pipe_inside/2023-03-10-10-31-02-001163.jpg  \n",
            "   creating: final_pipe_data/test/nothing/\n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-11-49-59-836302.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-11-59-42-313987.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-12-00-56-585532.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-12-22-00-059564.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-12-23-47-023748.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-12-24-57-969890.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-12-31-17-984962.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-12-32-13-936374.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-12-32-52-716732.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-12-34-33-420579.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-12-34-40-896020.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-10-13-15-05-884280.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-10-43-37-206340.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-10-46-14-197436.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-01-35-441772.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-17-19-880995.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-18-38-425800.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-19-17-407768.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-19-32-636673.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-20-18-290283.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-22-10-379101.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-24-50-567298.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-26-17-356185.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-26-56-033434.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-27-41-331438.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-39-56-772841.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-44-02-171323.jpg  \n",
            "  inflating: final_pipe_data/test/nothing/2023-03-13-11-44-31-835492.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -r tshirt_laptop_data"
      ],
      "metadata": {
        "id": "6gyRaAe-OwTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert all images to gray scale images"
      ],
      "metadata": {
        "id": "z34bvY1LT5Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_to_gray(rgb_img): # provide image in rgb order not in bgr or any other order\n",
        "\n",
        "  gamma = 1.04\n",
        "  r_const, g_const, b_const = 0.2126, 0.7152, 0.0722\n",
        "\n",
        "  r, g, b = rgb_img[:,:,0], rgb_img[:,:,1], rgb_img[:,:,2]\n",
        "\n",
        "  gray_img = r_const*r**gamma + g_const*g**gamma + b_const*b**gamma\n",
        "\n",
        "  return gray_img"
      ],
      "metadata": {
        "id": "luo_3LfmT_D-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grey_img = True\n",
        "\n",
        "import glob\n",
        "import cv2\n",
        "dir_name = \"/content/final_pipe_data\"+\"/*\"\n",
        "if grey_img:\n",
        "    for folder_name in glob.glob(dir_name):\n",
        "      for data_type_path in glob.glob(folder_name+\"/*\"):\n",
        "          for img_path in glob.glob(data_type_path+\"/*\"):\n",
        "              \n",
        "              img = cv2.imread(img_path) #BGR color map\n",
        "              rgb_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # BGR to RGB\n",
        "              gray = rgb_to_gray(rgb_img)\n",
        "              cv2.imwrite(img_path, gray)\n"
      ],
      "metadata": {
        "id": "tespa1ZdOwV3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NtmcEygSOjm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install specific tensorflow version "
      ],
      "metadata": {
        "id": "xPAXleRl6CPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==2.5.0"
      ],
      "metadata": {
        "id": "VCOBlSpL6Bvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c93b60f-82eb-4416-dd49-f396614bb3b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==2.5.0\n",
            "  Downloading tensorflow_gpu-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-gpu==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-gpu==2.5.0) (0.4.0)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 KB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.9/dist-packages (from tensorflow-gpu==2.5.0) (2.11.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.9/dist-packages (from tensorflow-gpu==2.5.0) (0.38.4)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-gpu==2.5.0) (3.19.6)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-gpu==2.5.0) (1.15.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-gpu==2.5.0) (3.1.0)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-gpu==2.5.0) (3.3.0)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow-gpu==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (2.2.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (2.16.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.0) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu==2.5.0) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.0) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.0) (4.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow-gpu==2.5.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu==2.5.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu==2.5.0) (3.2.2)\n",
            "Building wheels for collected packages: termcolor, wrapt\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=d1b7b1a10cc41aa003c6f646763e97eafb58d4844a2fb8a922227977b2ddd0b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp39-cp39-linux_x86_64.whl size=75953 sha256=7fd9eb9304726e3e9928fe1bfb171675967250ef0b8e9658af9b859df12dfa7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/23/68/efe259aaca055e93b08e74fbe512819c69a2155c11ba3c0f10\n",
            "Successfully built termcolor wrapt\n",
            "Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, keras-nightly, flatbuffers, numpy, grpcio, absl-py, keras-preprocessing, tensorflow-gpu\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.15.0\n",
            "    Uninstalling wrapt-1.15.0:\n",
            "      Successfully uninstalled wrapt-1.15.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.2.0\n",
            "    Uninstalling termcolor-2.2.0:\n",
            "      Successfully uninstalled termcolor-2.2.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.51.3\n",
            "    Uninstalling grpcio-1.51.3:\n",
            "      Successfully uninstalled grpcio-1.51.3\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.11.0 requires absl-py>=1.0.0, but you have absl-py 0.15.0 which is incompatible.\n",
            "tensorflow 2.11.0 requires flatbuffers>=2.0, but you have flatbuffers 1.12 which is incompatible.\n",
            "tensorflow 2.11.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.11.0 requires tensorflow-estimator<2.12,>=2.11.0, but you have tensorflow-estimator 2.5.0 which is incompatible.\n",
            "pydantic 1.10.5 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "jaxlib 0.4.4+cuda11.cudnn82 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.4.4 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.34.1 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.34.1 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "bokeh 2.4.3 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-0.15.0 flatbuffers-1.12 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 numpy-1.19.5 tensorflow-estimator-2.5.0 tensorflow-gpu-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5_FjV1k5_wg",
        "outputId": "f3d06809-c806-4b2d-c005-e3245d31a801"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3r7VVtk6AQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bcqcVYYjo6Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XwJ2vAJtpxRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDbcXfrRpxYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data in pipe line to tarin the model"
      ],
      "metadata": {
        "id": "JmT3vZhI31fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D,Dense,Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential"
      ],
      "metadata": {
        "id": "7jes4eSpQC1S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zOkBf541aeQm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 4\n",
        "BATCH_SIZE=32\n",
        "IMAGE_SIZE = 96\n",
        "NUM_CHANNEL = 1\n",
        "\n",
        "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE)\n",
        "MODEL_IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNEL)"
      ],
      "metadata": {
        "id": "TfsrnPgMaeS1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir='/content/final_pipe_data/train'\n",
        "val_data_dir='/content/final_pipe_data/test'\n",
        "\n",
        "# from tensorflow.keras.layers.preprocessing.image_preprocessing import HORIZONTAL\n",
        "\n",
        "train_datagen=ImageDataGenerator(#rescale=1./255, # 1./255 to scale\n",
        "                                 rotation_range=10,\n",
        "                                 width_shift_range=0.1,\n",
        "                                 height_shift_range=0.1,\n",
        "                                 horizontal_flip=True,\n",
        "                                 fill_mode='nearest')\n",
        "\n",
        "val_datagen=ImageDataGenerator(#rescale=1./255\n",
        "                               )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                  target_size=IMAGE_SHAPE,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  color_mode=\"grayscale\",\n",
        "                                                  class_mode='sparse')\n",
        "\n",
        "val_generator=val_datagen.flow_from_directory(val_data_dir,\n",
        "                                              target_size=IMAGE_SHAPE,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              color_mode=\"grayscale\",\n",
        "                                              class_mode='sparse')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCRDX1OyPk91",
        "outputId": "7a9391d1-117b-4463-e48e-efe126c07c5b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 images belonging to 4 classes.\n",
            "Found 110 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model"
      ],
      "metadata": {
        "id": "zL479Jog3oP_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_toJDoxJSrVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mobilenet V3 from scratch\n"
      ],
      "metadata": {
        "id": "AcZN5i1uQjtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code taken from here : https://github.com/sirius-ai/MobileNetV3-TF/blob/master/MobileNetV3.pyhttps://github.com/sirius-ai/MobileNetV3-TF/blob/master/MobileNetV3.py\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "MobileNetV3_Small_Spec = [\n",
        "    # Op            k    exp    out    SE     NL        s\n",
        "    [ \"ConvBnAct\",  3,   False, 16,    False, \"hswish\", 2 ],\n",
        "    [ \"bneck\",      3,   16,    16,    True,  \"relu\",   2 ],\n",
        "    [ \"bneck\",      3,   72,    24,    False, \"relu\",   2 ],\n",
        "    [ \"bneck\",      3,   88,    24,    False, \"relu\",   1 ],\n",
        "    [ \"bneck\",      5,   96,    40,    True,  \"hswish\", 2 ],\n",
        "    [ \"bneck\",      5,   240,   40,    True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   240,   40,    True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   120,   48,    True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   144,   48,    True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   288,   96,    True,  \"hswish\", 2 ],\n",
        "    [ \"bneck\",      5,   576,   96,    True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   576,   96,    True,  \"hswish\", 1 ],\n",
        "    [ \"ConvBnAct\",  1,   False, 576,   True,  \"hswish\", 1 ],\n",
        "    [ \"pool\",       7,   False, False, False, \"None\",   1 ],\n",
        "    [ \"ConvNBnAct\", 1,   False, 1280,  False, \"hswish\", 1 ],\n",
        "    [ \"ConvNBnAct\", 1,   False, 1000,  False, \"None\",   1 ],\n",
        "]\n",
        "\n",
        "\n",
        "MobileNetV3_Large_Spec = [\n",
        "    # Op            k    exp    out    SE     NL        s\n",
        "    [ \"ConvBnAct\",  3,   False, 16,    False, \"hswish\", 2 ],\n",
        "    [ \"bneck\",      3,   16,    16,    False, \"relu\",   1 ],\n",
        "    [ \"bneck\",      3,   64,    24,    False, \"relu\",   2 ],\n",
        "    [ \"bneck\",      3,   72,    24,    False, \"relu\",   1 ],\n",
        "    [ \"bneck\",      5,   72,    40,    True,  \"relu\",   2 ],\n",
        "    [ \"bneck\",      5,   120,   40,    True,  \"relu\",   1 ],\n",
        "    [ \"bneck\",      5,   120,   40,    True,  \"relu\",   1 ],\n",
        "    [ \"bneck\",      3,   240,   80,    False, \"hswish\", 2 ],\n",
        "    [ \"bneck\",      3,   200,   80,    False, \"hswish\", 1 ],\n",
        "    [ \"bneck\",      3,   184,   80,    False, \"hswish\", 1 ],\n",
        "    [ \"bneck\",      3,   184,   80,    False, \"hswish\", 1 ],\n",
        "    [ \"bneck\",      3,   480,   112,   True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      3,   672,   112,   True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   672,   160,   True,  \"hswish\", 2 ],\n",
        "    [ \"bneck\",      5,   960,   160,   True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   960,   160,   True,  \"hswish\", 1 ],\n",
        "    [ \"ConvBnAct\",  1,   False, 960,   False, \"hswish\", 1 ],\n",
        "    [ \"pool\",       7,   False, False, False, \"None\",   1 ],\n",
        "    [ \"ConvNBnAct\", 1,   False, 1280,  False, \"hswish\", 1 ],\n",
        "    [ \"ConvNBnAct\", 1,   False, 1000,  False, \"None\",   1 ],\n",
        "]\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "\n",
        "    return new_v\n",
        "\n",
        "class Identity(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=\"Identity\", **kwargs):\n",
        "        super(Identity, self).__init__(name=name, **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        return input\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(Identity, self).get_config()\n",
        "        return dict(list(base_config.items()))\n",
        "\n",
        "class HardSigmoid(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=\"HardSigmoid\", **kwargs):\n",
        "        super(HardSigmoid, self).__init__(name=name, **kwargs)\n",
        "        self.relu6 = tf.keras.layers.ReLU(max_value=6, name=\"ReLU6\", **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        return self.relu6(input + 3.0) / 6.0\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(HardSigmoid, self).get_config()\n",
        "        return dict(list(base_config.items()))\n",
        "\n",
        "class HardSwish(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=\"HardSwish\", **kwargs):\n",
        "        super(HardSwish, self).__init__(name=name, **kwargs)\n",
        "        self.relu6 = tf.keras.layers.ReLU(max_value=6, name=\"ReLU6\", **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        return input * self.relu6(input + 3.0) / 6.0\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(HardSwish, self).get_config()\n",
        "        return dict(list(base_config.items()))\n",
        "\n",
        "_available_activation = {\n",
        "            \"relu\": tf.keras.layers.ReLU(name=\"ReLU\"),\n",
        "            \"relu6\": tf.keras.layers.ReLU(max_value=6, name=\"ReLU6\"),\n",
        "            \"hswish\": HardSwish(),\n",
        "            \"hsigmoid\": HardSigmoid(),\n",
        "            \"softmax\": tf.keras.layers.Softmax(name=\"Softmax\"),\n",
        "            \"None\": Identity(),\n",
        "        }\n",
        "\n",
        "class SENet(tf.keras.layers.Layer):\n",
        "    def __init__(self, reduction=4, l2=2e-4, name=\"SENet\", **kwargs):\n",
        "        super(SENet, self).__init__(name=name, **kwargs)\n",
        "        self.reduction = reduction\n",
        "        self.l2 = l2\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, h, w, c = input_shape\n",
        "        self.gap = tf.keras.layers.GlobalAveragePooling2D(name=f'AvgPool{h}x{w}')\n",
        "        self.fc1 = tf.keras.layers.Dense(units=c//self.reduction, activation=\"relu\", use_bias=False,\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(self.l2), name=\"Squeeze\")\n",
        "        self.fc2 = tf.keras.layers.Dense(units=c, activation=HardSigmoid(), use_bias=False,\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(self.l2), name=\"Excite\")\n",
        "        self.reshape = tf.keras.layers.Reshape((1, 1, c), name=f'Reshape_None_1_1_{c}')\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.gap(input)\n",
        "        output = self.fc1(output)\n",
        "        output = self.fc2(output)\n",
        "        output = self.reshape(output)\n",
        "        return input * output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"reduction\":self.reduction, \"l2\":self.l2}\n",
        "        base_config = super(SENet, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class ConvBnAct(tf.keras.layers.Layer):\n",
        "    def __init__(self, k, exp, out, SE, NL, s, l2, name=\"ConvBnAct\", **kwargs):\n",
        "        super(ConvBnAct, self).__init__(name=name, **kwargs)\n",
        "        self.k = k\n",
        "        self.exp = exp\n",
        "        self.out = out\n",
        "        self.se = SE\n",
        "        self.nl = NL\n",
        "        self.s = s\n",
        "        self.l2 = l2\n",
        "        self.conv2d = tf.keras.layers.Conv2D(filters=out, kernel_size=k, strides=s, activation=None, padding=\"same\",\n",
        "                                             kernel_regularizer=tf.keras.regularizers.l2(l2), name=\"conv2d\", **kwargs)\n",
        "        self.bn = tf.keras.layers.BatchNormalization(momentum=0.99, name=\"BatchNormalization\", **kwargs)\n",
        "        self.act = _available_activation[NL]\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.conv2d(input)\n",
        "        output = self.bn(output)\n",
        "        output = self.act(output)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"k\":self.k, \"exp\":self.exp, \"out\":self.out, \"SE\":self.se, \"NL\":self.nl, \"s\":self.s, \"l2\":self.l2}\n",
        "        base_config = super(ConvBnAct, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class ConvNBnAct(tf.keras.layers.Layer):\n",
        "    def __init__(self, k, exp, out, SE, NL, s, l2, name=\"ConvNBnAct\", **kwargs):\n",
        "        super(ConvNBnAct, self).__init__(name=name, **kwargs)\n",
        "        self.k = k\n",
        "        self.exp = exp\n",
        "        self.out = out\n",
        "        self.se = SE\n",
        "        self.nl = NL\n",
        "        self.s = s\n",
        "        self.l2 = l2\n",
        "        self.act = _available_activation[NL]\n",
        "        self.fn = tf.keras.layers.Conv2D(filters=out, kernel_size=k, strides=s, activation=self.act, padding=\"same\",\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(l2),name=\"conv2d\", **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.fn(input)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"k\":self.k, \"exp\":self.exp, \"out\":self.out, \"SE\":self.se, \"NL\":self.nl, \"s\":self.s, \"l2\":self.l2}\n",
        "        base_config = super(ConvNBnAct, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class Pool(tf.keras.layers.Layer):\n",
        "    def __init__(self, k, exp, out, SE, NL, s, l2, name=\"Pool\", **kwargs):\n",
        "        super(Pool, self).__init__(name=name, **kwargs)\n",
        "        self.k = k\n",
        "        self.exp = exp\n",
        "        self.out = out\n",
        "        self.se = SE\n",
        "        self.nl = NL\n",
        "        self.s = s\n",
        "        self.l2 = l2\n",
        "        self.gap = tf.keras.layers.AveragePooling2D(pool_size=(k, k), strides=1, name=f'AvgPool{k}x{k}', **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.gap(input)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"k\":self.k, \"exp\":self.exp, \"out\":self.out, \"SE\":self.se, \"NL\":self.nl, \"s\":self.s, \"l2\":self.l2}\n",
        "        base_config = super(Pool, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class BottleNeck(tf.keras.layers.Layer):\n",
        "    def __init__(self, k, exp, out, SE, NL, s, l2, name=\"BottleNeck\", **kwargs):\n",
        "        super(BottleNeck, self).__init__(name=name, **kwargs)\n",
        "        self.k = k\n",
        "        self.exp = exp\n",
        "        self.out = out\n",
        "        self.se = SE\n",
        "        self.nl = NL\n",
        "        self.s = s\n",
        "        self.l2 = l2\n",
        "        self.expand = ConvBnAct(k=1, exp=exp, out=exp, SE=SE, NL=NL, s=1, l2=l2, name=\"BottleNeckExpand\", **kwargs)\n",
        "        self.depthwise = tf.keras.layers.DepthwiseConv2D(\n",
        "            kernel_size=k,\n",
        "            strides=s,\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            depthwise_regularizer=tf.keras.regularizers.l2(l2),\n",
        "            name=f'Depthwise{k}x{k}',\n",
        "            ** kwargs,\n",
        "        )\n",
        "        self.pointwise = tf.keras.layers.Conv2D(\n",
        "            filters=out,\n",
        "            kernel_size=1,\n",
        "            strides=1,\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2),\n",
        "            name=f'Pointwise1x1',\n",
        "            ** kwargs,\n",
        "        )\n",
        "        self.bn_1 = tf.keras.layers.BatchNormalization(momentum=0.99, name=\"BatchNormalization_1\", **kwargs)\n",
        "        self.bn_2 = tf.keras.layers.BatchNormalization(momentum=0.99, name=\"BatchNormalization_2\", **kwargs)\n",
        "\n",
        "        if self.se:\n",
        "            self.SeNet = SENet(name=\"SEBottleneck\", l2=l2, **kwargs)\n",
        "\n",
        "        self.act = _available_activation[NL]\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.expand(input)\n",
        "        output = self.depthwise(output)\n",
        "        output = self.bn_1(output)\n",
        "        if self.se:\n",
        "            output = self.SeNet(output)\n",
        "        output = self.act(output)\n",
        "        output = self.pointwise(output)\n",
        "        output = self.bn_2(output)\n",
        "\n",
        "        if self.s == 1 and self.exp == self.out:\n",
        "            return input + output\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"k\":self.k, \"exp\":self.exp, \"out\":self.out, \"SE\":self.se, \"NL\":self.nl, \"s\":self.s, \"l2\":self.l2}\n",
        "        base_config = super(BottleNeck, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "_available_mobilenetv3_spec = {\n",
        "            \"small\": MobileNetV3_Small_Spec,\n",
        "            \"large\": MobileNetV3_Large_Spec,\n",
        "        }\n",
        "\n",
        "_available_operation = {\n",
        "            \"ConvBnAct\":  ConvBnAct,\n",
        "            \"bneck\":      BottleNeck,\n",
        "            \"pool\":       Pool,\n",
        "            \"ConvNBnAct\": ConvNBnAct,\n",
        "        }\n",
        "\n",
        "class CusReshape(tf.keras.layers.Layer):\n",
        "    def __init__(self, out, name=\"Reshape\", **kwargs):\n",
        "        super(CusReshape, self).__init__(name=name, **kwargs)\n",
        "        self.out = out\n",
        "        self.reshape = tf.keras.layers.Reshape((out,), name=f'Reshape_None_{out}', **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.reshape(input)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"out\":self.out}\n",
        "        base_config = super(CusReshape, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class CusDropout(tf.keras.layers.Layer):\n",
        "    def __init__(self, dropout_rate, name=\"Dropout\", **kwargs):\n",
        "        super(CusDropout, self).__init__(name=name, **kwargs)\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=dropout_rate, name=f'Dropout', **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.dropout(input)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"dropout_rate\":self.dropout_rate}\n",
        "        base_config = super(CusDropout, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "def MobileNetV3(type=\"large\", input_shape=(224, 224, 3), classes_number=2, width_multiplier=1.0,\n",
        "                divisible_by=8, l2_reg=2e-5, dropout_rate=0.2, name=\"MobileNetV3\"):\n",
        "    spec = _available_mobilenetv3_spec[type]\n",
        "    spec[-1][3] = classes_number  # bottlenet layer size or class numbers\n",
        "    name = name + \"_\" + type\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape, name=\"inputs\")\n",
        "\n",
        "    for i, params in enumerate(spec):\n",
        "        Op, k, exp, out, SE, NL, s = params\n",
        "        inference_op = _available_operation[Op]\n",
        "\n",
        "        if isinstance(exp, int):\n",
        "            exp_ch = _make_divisible(exp * width_multiplier, divisible_by)\n",
        "        else:\n",
        "            exp_ch = None\n",
        "        if isinstance(out, int):\n",
        "            out_ch = _make_divisible(out * width_multiplier, divisible_by)\n",
        "        else:\n",
        "            out_ch = None\n",
        "        if i == len(spec) - 1:  # fix output classes error.\n",
        "            out_ch = classes_number\n",
        "\n",
        "        op_name = f'{Op}_{i}'\n",
        "        if i == 0:\n",
        "            output = inference_op(k, exp_ch, out_ch, SE, NL, s, l2_reg, op_name)(inputs)\n",
        "        else:\n",
        "            output = inference_op(k, exp_ch, out_ch, SE, NL, s, l2_reg, op_name)(output)\n",
        "\n",
        "        if (type == \"small\" and i == 14) or (type == \"large\" and i == 18):\n",
        "            output = CusDropout(dropout_rate=dropout_rate)(output)\n",
        "\n",
        "    outputs = CusReshape(out=classes_number)(output)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "custom_objects = {\n",
        "    \"ConvBnAct\" :  ConvBnAct,\n",
        "    \"BottleNeck\":  BottleNeck,\n",
        "    \"Pool\"      :  Pool,\n",
        "    \"ConvNBnAct\":  ConvNBnAct,\n",
        "    \"CusReshape\":  CusReshape,\n",
        "    \"CusDropout\":  CusDropout,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
        "    tf.compat.v2.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "model = MobileNetV3(type=\"small\")\n",
        "\n",
        "# model = MobileNetV3(type=\"large\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dcS0I4yDANn",
        "outputId": "8ad0efb8-46dc-4b2a-c8e6-e634ececbe26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"MobileNetV3_small\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " ConvBnAct_0 (ConvBnAct)     (None, 112, 112, 16)      512       \n",
            "                                                                 \n",
            " bneck_1 (BottleNeck)        (None, 56, 56, 16)        992       \n",
            "                                                                 \n",
            " bneck_2 (BottleNeck)        (None, 28, 28, 24)        4272      \n",
            "                                                                 \n",
            " bneck_3 (BottleNeck)        (None, 28, 28, 24)        5904      \n",
            "                                                                 \n",
            " bneck_4 (BottleNeck)        (None, 14, 14, 40)        14176     \n",
            "                                                                 \n",
            " bneck_5 (BottleNeck)        (None, 14, 14, 40)        56320     \n",
            "                                                                 \n",
            " bneck_6 (BottleNeck)        (None, 14, 14, 40)        56320     \n",
            "                                                                 \n",
            " bneck_7 (BottleNeck)        (None, 14, 14, 48)        22032     \n",
            "                                                                 \n",
            " bneck_8 (BottleNeck)        (None, 14, 14, 48)        29280     \n",
            "                                                                 \n",
            " bneck_9 (BottleNeck)        (None, 7, 7, 96)          93120     \n",
            "                                                                 \n",
            " bneck_10 (BottleNeck)       (None, 7, 7, 96)          296448    \n",
            "                                                                 \n",
            " bneck_11 (BottleNeck)       (None, 7, 7, 96)          296448    \n",
            "                                                                 \n",
            " ConvBnAct_12 (ConvBnAct)    (None, 7, 7, 576)         58176     \n",
            "                                                                 \n",
            " pool_13 (Pool)              (None, 1, 1, 576)         0         \n",
            "                                                                 \n",
            " ConvNBnAct_14 (ConvNBnAct)  (None, 1, 1, 1280)        738560    \n",
            "                                                                 \n",
            " Dropout (CusDropout)        (None, 1, 1, 1280)        0         \n",
            "                                                                 \n",
            " ConvNBnAct_15 (ConvNBnAct)  (None, 1, 1, 2)           2562      \n",
            "                                                                 \n",
            " Reshape (CusReshape)        (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,675,122\n",
            "Trainable params: 1,662,978\n",
            "Non-trainable params: 12,144\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def conv_block(inputs, filters, kernel_size, strides, use_bias=True):\n",
        "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same', use_bias=use_bias)(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def depthwise_conv_block(inputs, strides, use_bias=True):\n",
        "    x = tf.keras.layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=use_bias)(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "\n",
        "def bottleneck(inputs, filters, kernel_size, expansion_factor, strides, use_bias=True):\n",
        "    in_channels = inputs.shape[-1]\n",
        "    x = depthwise_conv_block(inputs, 1, use_bias)\n",
        "    x = depthwise_conv_block(x, 1 use_bias)\n",
        "    x = tf.keras.layers.Conv2D(filters, 1, strides=1, padding='same', use_bias=use_bias)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if strides == 1 and in_channels == filters:\n",
        "        x = tf.keras.layers.Add()([x, inputs])\n",
        "    return x\n",
        "\n",
        "def mobilenetv3_small(input_shape, num_classes):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "\n",
        "    # # x3 = tf.keras.layers.Conv2D(1, 3, strides=1, padding='valid', use_bias=True)(inputs)\n",
        "    # # x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "    # # x3 = tf.keras.layers.ReLU()(x3)\n",
        "    x1 = tf.keras.layers.AveragePooling2D(pool_size=(5, 5), strides=3)(inputs)\n",
        "    x2 = tf.keras.layers.MaxPooling2D(pool_size=(5, 5), strides=3)(inputs)\n",
        "    x = tf.keras.layers.Concatenate()([x1, x2])\n",
        "\n",
        "    x = conv_block(x, 4, 3, strides=2)\n",
        "    x = bottleneck(x, 6, 3, expansion_factor=1, strides=2)\n",
        "    x = bottleneck(x, 6, 5, expansion_factor=1, strides=1)\n",
        "    x = bottleneck(x, 6, 5, expansion_factor=1, strides=1)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=2)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=1)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=1)\n",
        "    # x = conv_block(x, 8, 1, strides=1)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(48)(x)\n",
        "    x = tf.keras.layers.ReLU(6.)(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "# example usage\n",
        "model = mobilenetv3_small(input_shape=MODEL_IMAGE_SHAPE, num_classes=NUM_CLASSES)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "Acg6NyiO_2KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def conv_block(inputs, filters, kernel_size, strides, use_bias=True):\n",
        "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same', use_bias=use_bias)(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def depthwise_conv_block(inputs, strides, use_bias=True):\n",
        "    x = tf.keras.layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=use_bias)(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "\n",
        "def bottleneck(inputs, filters, kernel_size, expansion_factor, strides, use_bias=True):\n",
        "    in_channels = inputs.shape[-1]\n",
        "    x = conv_block(inputs, expansion_factor * in_channels, 1, 1, use_bias)\n",
        "    x = conv_block(x, expansion_factor * in_channels, kernel_size, strides, use_bias)\n",
        "    x = tf.keras.layers.Conv2D(filters, 1, strides=1, padding='same', use_bias=use_bias)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if strides == 1 and in_channels == filters:\n",
        "        x = tf.keras.layers.Add()([x, inputs])\n",
        "    return x\n",
        "\n",
        "def mobilenetv3_small(input_shape, num_classes):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    x1 = tf.keras.layers.AveragePooling2D(pool_size=(5, 5), strides=3)(inputs)\n",
        "    x2 = tf.keras.layers.MaxPooling2D(pool_size=(5, 5), strides=3)(inputs)\n",
        "    # # x3 = tf.keras.layers.Conv2D(1, 3, strides=1, padding='valid', use_bias=True)(inputs)\n",
        "    # # x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "    # # x3 = tf.keras.layers.ReLU()(x3)\n",
        "    x = tf.keras.layers.Concatenate()([x1, x2])\n",
        "\n",
        "    x = conv_block(x, 4, 3, strides=2)\n",
        "    x = bottleneck(x, 6, 3, expansion_factor=1, strides=2)\n",
        "    x = bottleneck(x, 6, 5, expansion_factor=1, strides=1)\n",
        "    x = bottleneck(x, 6, 5, expansion_factor=1, strides=1)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=2)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=1)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=1)\n",
        "    # x = conv_block(x, 8, 1, strides=1)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(48)(x)\n",
        "    x = tf.keras.layers.ReLU(6.)(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "# example usage\n",
        "model = mobilenetv3_small(input_shape=MODEL_IMAGE_SHAPE, num_classes=NUM_CLASSES)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmgpFEkKTMYF",
        "outputId": "16d2b768-c5cf-4dd0-ffff-6996a5ba50b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_30 (InputLayer)           [(None, 96, 96, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 31, 31, 1)    0           input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 31, 31, 1)    0           input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 31, 31, 2)    0           average_pooling2d_13[0][0]       \n",
            "                                                                 max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 16, 16, 4)    76          concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 16, 16, 4)    16          conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_360 (ReLU)                (None, 16, 16, 4)    0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 16, 16, 4)    20          re_lu_360[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 16, 16, 4)    16          conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_361 (ReLU)                (None, 16, 16, 4)    0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 8, 8, 4)      148         re_lu_361[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 8, 8, 4)      16          conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_362 (ReLU)                (None, 8, 8, 4)      0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 8, 8, 6)      30          re_lu_362[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 8, 8, 6)      24          conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 8, 8, 6)      42          batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 8, 8, 6)      24          conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_363 (ReLU)                (None, 8, 8, 6)      0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 8, 8, 6)      906         re_lu_363[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 8, 8, 6)      24          conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_364 (ReLU)                (None, 8, 8, 6)      0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 8, 8, 6)      42          re_lu_364[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 8, 8, 6)      24          conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 8, 8, 6)      0           batch_normalization_266[0][0]    \n",
            "                                                                 batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 8, 8, 6)      42          add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 8, 8, 6)      24          conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_365 (ReLU)                (None, 8, 8, 6)      0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 8, 8, 6)      906         re_lu_365[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 8, 8, 6)      24          conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_366 (ReLU)                (None, 8, 8, 6)      0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 8, 8, 6)      42          re_lu_366[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 8, 8, 6)      24          conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_76 (Add)                    (None, 8, 8, 6)      0           batch_normalization_269[0][0]    \n",
            "                                                                 add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_25 (Gl (None, 6)            0           add_76[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 48)           336         global_average_pooling2d_25[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "re_lu_367 (ReLU)                (None, 48)           0           dense_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 2)            98          re_lu_367[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,904\n",
            "Trainable params: 2,796\n",
            "Non-trainable params: 108\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b8PE09TtfZqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mobilenet V2 from scratch"
      ],
      "metadata": {
        "id": "kDn6fRqASmYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def conv_block(inputs, filters, kernel_size, strides):\n",
        "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def bottleneck(inputs, filters, kernel_size, t, strides, use_bias=False):\n",
        "    in_channels = inputs.shape[-1]\n",
        "    x = conv_block(inputs, t * in_channels, 1, 1)\n",
        "    x = tf.keras.layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=use_bias)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Conv2D(filters, 1, strides=1, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if strides == 1 and in_channels == filters:\n",
        "        x = tf.keras.layers.Add()([x, inputs])\n",
        "    return x\n",
        "\n",
        "def mobilenetv2(input_shape, num_classes):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = conv_block(inputs, 32, 3, strides=2)\n",
        "    x = bottleneck(x, 16, 3, t=1, strides=1)\n",
        "    x = bottleneck(x, 24, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 24, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 32, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 32, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 64, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 64, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 96, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 96, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 160, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 160, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 320, 3, t=6, strides=1)\n",
        "    x = conv_block(x, 1280, 1, strides=1)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "# example usage\n",
        "model = mobilenetv2(input_shape=(224, 224, 3), num_classes=10)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "pWJ5vXIxSuT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n-unizCWTh9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-56JCIhBTh_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "#tf.keras.applications.MobileNetV3Small\n",
        "\n",
        "base_model = MobileNetV3Large(\n",
        "    input_shape=MODEL_IMAGE_SHAPE,\n",
        "    alpha=0.4,\n",
        "    include_top=False,\n",
        "    weights=None, #  'imagenet'\n",
        "    #input_tensor=None,\n",
        "    #pooling=None,\n",
        "    #classes=1000,\n",
        "    #classifier_activation='softmax',\n",
        "    #**kwargs\n",
        ")\n",
        "\n",
        "for layer in base_model.layers: #base_model.layers[:-6] means that consider layer only till 6th last layer from layer 1\n",
        "    layer.trainable = True  \n",
        "\n",
        "\n",
        "\n",
        "# penultimate_layer = model.layers[-2]\n",
        "# new_top_layer = tf.keras.layers.Dense(1)(penultimate_layer.output)  # create new FC layer and connect it to the rest of the model\n",
        "# new_model = tf.keras.models.Model(model.input, new_top_layer)\n",
        "\n",
        "\n",
        "\n",
        "# Use a Sequential model to add a trainable classifier on top\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y6FsGLvTMbA",
        "outputId": "cdeef9eb-7de9-4f48-f03c-2f09a6c10cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "MobilenetV3large (Functional (None, 3, 3, 1280)        1031008   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_17  (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 64)                81984     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 1,113,122\n",
            "Trainable params: 1,102,962\n",
            "Non-trainable params: 10,160\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### MobileNetV2"
      ],
      "metadata": {
        "id": "qomxkZHNIlYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/Haikoitoh/paper-implementation/blob/main/MobileNetV2.ipynb\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, ReLU, BatchNormalization, add,Softmax, AveragePooling2D, Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def expansion_block(x,t,filters,block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "    total_filters = t*filters\n",
        "    x = Conv2D(total_filters,1,padding='same',use_bias=False, name = prefix +'expand')(x)\n",
        "    x = BatchNormalization(name=prefix +'expand_bn')(x)\n",
        "    x = ReLU(6,name = prefix +'expand_relu')(x)\n",
        "    return x\n",
        "\n",
        "def depthwise_block(x,stride,block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "    x = DepthwiseConv2D(3,strides=(stride,stride),padding ='same', use_bias = False, name = prefix + 'depthwise_conv')(x)\n",
        "    x = BatchNormalization(name=prefix +'dw_bn')(x)\n",
        "    x = ReLU(6,name=prefix +'dw_relu')(x)\n",
        "    return x\n",
        "\n",
        "def projection_block(x,out_channels,block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "    x = Conv2D(filters = out_channels,kernel_size = 1,padding='same',use_bias=False,name= prefix + 'compress')(x)\n",
        "    x = BatchNormalization(name=prefix +'compress_bn')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def Bottleneck(x,t,filters, out_channels,stride,block_id):\n",
        "    y = expansion_block(x,t,filters,block_id)\n",
        "    y = depthwise_block(y,stride,block_id)\n",
        "    y = projection_block(y, out_channels,block_id)\n",
        "    if y.shape[-1]==x.shape[-1]:\n",
        "        y = add([x,y])\n",
        "    return y\n",
        "\n",
        "\n",
        "def MobileNetV2(input_image = (224,224,3), n_classes=1000):\n",
        "    input = Input(input_image)\n",
        "\n",
        "    x1 = tf.keras.layers.AveragePooling2D(pool_size=(5, 5), strides=3)(input)\n",
        "    x2 = tf.keras.layers.MaxPooling2D(pool_size=(5, 5), strides=3)(input)\n",
        "    x = tf.keras.layers.Concatenate()([x1, x2])    \n",
        "\n",
        "    x = Conv2D(1,kernel_size=3,strides=(2,2),padding = 'same', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='conv1_bn')(x)\n",
        "    x = ReLU(6, name = 'conv1_relu')(x)\n",
        "\n",
        "    # 17 Bottlenecks\n",
        "\n",
        "    x = depthwise_block(x,stride=1,block_id=1)\n",
        "    x = projection_block(x, out_channels=4,block_id=1)\n",
        "\n",
        "    x = Bottleneck(x, t = 1, filters = x.shape[-1], out_channels = 6, stride = 2,block_id = 2)\n",
        "    x = Bottleneck(x, t = 1, filters = x.shape[-1], out_channels = 6, stride = 1,block_id = 3)\n",
        "\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 2,block_id = 4)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 5)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 6)\n",
        "\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 2,block_id = 7)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 8)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 9)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 10)\n",
        "\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 11)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 12)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 13)\n",
        "\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 2,block_id = 14)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 15)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 16)\n",
        "\n",
        "    # x = Bottleneck(x, t = 2, filters = x.shape[-1], out_channels = 8, stride = 1,block_id = 17)\n",
        "\n",
        "\n",
        "    #1*1 conv\n",
        "    x = Conv2D(filters = 6,kernel_size = 1,padding='same',use_bias=False, name = 'last_conv')(x)\n",
        "    x = BatchNormalization(name='last_bn')(x)\n",
        "    x = ReLU(6,name='last_relu')(x)\n",
        "\n",
        "    #AvgPool 7*7\n",
        "    x = GlobalAveragePooling2D(name='global_average_pool')(x)\n",
        "    x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    output = Dense(n_classes,activation='softmax')(x)\n",
        "\n",
        "    model = Model(input, output)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# n_classes = 1000\n",
        "# input_shape = (224,224,3)\n",
        "\n",
        "# model = MobileNetV2(input_shape,n_classes)\n",
        "# model.summary()   \n",
        "\n",
        "model = MobileNetV2(MODEL_IMAGE_SHAPE, NUM_CLASSES)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYtHrRENIRuh",
        "outputId": "6627f618-dceb-45f2-819e-7491afd03895"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 96, 96, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 31, 31, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 31, 31, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 31, 31, 2)    0           average_pooling2d[0][0]          \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 16, 16, 1)    18          concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 16, 1)    4           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (ReLU)               (None, 16, 16, 1)    0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_conv (Depthwi (None, 16, 16, 1)    9           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block_1_dw_bn (BatchNormalizati (None, 16, 16, 1)    4           block_1_depthwise_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_1_dw_relu (ReLU)          (None, 16, 16, 1)    0           block_1_dw_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_1_compress (Conv2D)       (None, 16, 16, 4)    4           block_1_dw_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_1_compress_bn (BatchNorma (None, 16, 16, 4)    16          block_1_compress[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand (Conv2D)         (None, 16, 16, 4)    16          block_1_compress_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_bn (BatchNormali (None, 16, 16, 4)    16          block_2_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_relu (ReLU)      (None, 16, 16, 4)    0           block_2_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_conv (Depthwi (None, 8, 8, 4)      36          block_2_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_dw_bn (BatchNormalizati (None, 8, 8, 4)      16          block_2_depthwise_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_dw_relu (ReLU)          (None, 8, 8, 4)      0           block_2_dw_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_2_compress (Conv2D)       (None, 8, 8, 6)      24          block_2_dw_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_compress_bn (BatchNorma (None, 8, 8, 6)      24          block_2_compress[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand (Conv2D)         (None, 8, 8, 6)      36          block_2_compress_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_bn (BatchNormali (None, 8, 8, 6)      24          block_3_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_relu (ReLU)      (None, 8, 8, 6)      0           block_3_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_conv (Depthwi (None, 8, 8, 6)      54          block_3_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_dw_bn (BatchNormalizati (None, 8, 8, 6)      24          block_3_depthwise_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_dw_relu (ReLU)          (None, 8, 8, 6)      0           block_3_dw_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_3_compress (Conv2D)       (None, 8, 8, 6)      36          block_3_dw_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_3_compress_bn (BatchNorma (None, 8, 8, 6)      24          block_3_compress[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 8, 8, 6)      0           block_2_compress_bn[0][0]        \n",
            "                                                                 block_3_compress_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "last_conv (Conv2D)              (None, 8, 8, 6)      36          add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "last_bn (BatchNormalization)    (None, 8, 8, 6)      24          last_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last_relu (ReLU)                (None, 8, 8, 6)      0           last_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pool (GlobalAver (None, 6)            0           last_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           224         global_average_pool[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            132         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 801\n",
            "Trainable params: 713\n",
            "Non-trainable params: 88\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5rEhalrFQqzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTSIpJVBf1SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWLnw7k10FCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKUvSSdATMgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3A8Mw3LXPlAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "FN6vf2wB3juX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"image_classification_checkpoint.h5\",\n",
        "                             monitor='val_loss',\n",
        "                             mode='min',\n",
        "                             save_best_only=True,verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=2,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True)\n",
        "\n",
        "callbacks=[checkpoint,earlystop]\n",
        "\n",
        "model.compile(loss='SparseCategoricalCrossentropy',\n",
        "                   optimizer=Adam(learning_rate=0.0015),\n",
        "                   metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "epochs=500\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                        #  steps_per_epoch=num_train_samples//batch_size,\n",
        "                         epochs=epochs,\n",
        "                        #  callbacks=callbacks,\n",
        "                         validation_data=val_generator,\n",
        "                        #  validation_steps=num_val_samples//batch_size\n",
        "                         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZywXeOe_SQnj",
        "outputId": "9b7fb84f-361a-48b9-dcd9-223b0726f04f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "25/25 [==============================] - 13s 273ms/step - loss: 0.7363 - sparse_categorical_accuracy: 0.7262 - val_loss: 1.5137 - val_sparse_categorical_accuracy: 0.3000\n",
            "Epoch 2/500\n",
            "25/25 [==============================] - 3s 110ms/step - loss: 0.7291 - sparse_categorical_accuracy: 0.6963 - val_loss: 0.9388 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 3/500\n",
            "25/25 [==============================] - 4s 146ms/step - loss: 0.7006 - sparse_categorical_accuracy: 0.7300 - val_loss: 0.6831 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 4/500\n",
            "25/25 [==============================] - 4s 155ms/step - loss: 0.7184 - sparse_categorical_accuracy: 0.7138 - val_loss: 1.3431 - val_sparse_categorical_accuracy: 0.5182\n",
            "Epoch 5/500\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.7343 - sparse_categorical_accuracy: 0.6900 - val_loss: 0.8290 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 6/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.7098 - sparse_categorical_accuracy: 0.7200 - val_loss: 1.7640 - val_sparse_categorical_accuracy: 0.3818\n",
            "Epoch 7/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.7191 - sparse_categorical_accuracy: 0.7237 - val_loss: 1.4970 - val_sparse_categorical_accuracy: 0.4364\n",
            "Epoch 8/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.7118 - sparse_categorical_accuracy: 0.7050 - val_loss: 1.1996 - val_sparse_categorical_accuracy: 0.5455\n",
            "Epoch 9/500\n",
            "25/25 [==============================] - 3s 126ms/step - loss: 0.7131 - sparse_categorical_accuracy: 0.7237 - val_loss: 1.3561 - val_sparse_categorical_accuracy: 0.4636\n",
            "Epoch 10/500\n",
            "25/25 [==============================] - 4s 154ms/step - loss: 0.7049 - sparse_categorical_accuracy: 0.7275 - val_loss: 1.6068 - val_sparse_categorical_accuracy: 0.4545\n",
            "Epoch 11/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.7236 - sparse_categorical_accuracy: 0.7113 - val_loss: 1.6227 - val_sparse_categorical_accuracy: 0.4364\n",
            "Epoch 12/500\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.7240 - sparse_categorical_accuracy: 0.7138 - val_loss: 1.2500 - val_sparse_categorical_accuracy: 0.5273\n",
            "Epoch 13/500\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.7054 - sparse_categorical_accuracy: 0.7225 - val_loss: 1.0718 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 14/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.7138 - val_loss: 0.9023 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 15/500\n",
            "25/25 [==============================] - 3s 137ms/step - loss: 0.7509 - sparse_categorical_accuracy: 0.7063 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 16/500\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 0.7134 - sparse_categorical_accuracy: 0.7175 - val_loss: 0.7319 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 17/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.7068 - sparse_categorical_accuracy: 0.7075 - val_loss: 0.7436 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 18/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.7205 - sparse_categorical_accuracy: 0.7212 - val_loss: 0.6338 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 19/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.7184 - sparse_categorical_accuracy: 0.7113 - val_loss: 0.9351 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 20/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.7088 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.8628 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 21/500\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.6871 - sparse_categorical_accuracy: 0.7287 - val_loss: 1.3284 - val_sparse_categorical_accuracy: 0.5273\n",
            "Epoch 22/500\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.7319 - sparse_categorical_accuracy: 0.7075 - val_loss: 1.0604 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 23/500\n",
            "25/25 [==============================] - 4s 152ms/step - loss: 0.7107 - sparse_categorical_accuracy: 0.7212 - val_loss: 1.1917 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 24/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.7059 - sparse_categorical_accuracy: 0.7237 - val_loss: 1.0378 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 25/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.7264 - sparse_categorical_accuracy: 0.7200 - val_loss: 1.1078 - val_sparse_categorical_accuracy: 0.5636\n",
            "Epoch 26/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6840 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.7568 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 27/500\n",
            "25/25 [==============================] - 3s 116ms/step - loss: 0.7122 - sparse_categorical_accuracy: 0.7100 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 28/500\n",
            "25/25 [==============================] - 3s 135ms/step - loss: 0.6930 - sparse_categorical_accuracy: 0.7475 - val_loss: 1.0935 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 29/500\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.7116 - sparse_categorical_accuracy: 0.7175 - val_loss: 0.8224 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 30/500\n",
            "25/25 [==============================] - 2s 89ms/step - loss: 0.7289 - sparse_categorical_accuracy: 0.7025 - val_loss: 0.8009 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 31/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6965 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.7787 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 32/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6869 - sparse_categorical_accuracy: 0.7300 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 33/500\n",
            "25/25 [==============================] - 4s 160ms/step - loss: 0.7370 - sparse_categorical_accuracy: 0.7063 - val_loss: 1.1001 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 34/500\n",
            "25/25 [==============================] - 3s 126ms/step - loss: 0.7064 - sparse_categorical_accuracy: 0.7200 - val_loss: 1.5463 - val_sparse_categorical_accuracy: 0.4455\n",
            "Epoch 35/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.7028 - sparse_categorical_accuracy: 0.7150 - val_loss: 1.1466 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 36/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6922 - sparse_categorical_accuracy: 0.7425 - val_loss: 1.2360 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 37/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.7322 - sparse_categorical_accuracy: 0.7025 - val_loss: 1.0320 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 38/500\n",
            "25/25 [==============================] - 4s 161ms/step - loss: 0.7029 - sparse_categorical_accuracy: 0.7225 - val_loss: 0.9536 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 39/500\n",
            "25/25 [==============================] - 5s 185ms/step - loss: 0.7097 - sparse_categorical_accuracy: 0.7250 - val_loss: 1.1843 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 40/500\n",
            "25/25 [==============================] - 4s 170ms/step - loss: 0.6830 - sparse_categorical_accuracy: 0.7362 - val_loss: 1.0280 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 41/500\n",
            "25/25 [==============================] - 3s 116ms/step - loss: 0.7031 - sparse_categorical_accuracy: 0.7200 - val_loss: 1.3868 - val_sparse_categorical_accuracy: 0.4818\n",
            "Epoch 42/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6886 - sparse_categorical_accuracy: 0.7212 - val_loss: 1.2116 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 43/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.7362 - val_loss: 1.0070 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 44/500\n",
            "25/25 [==============================] - 3s 134ms/step - loss: 0.6701 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.9187 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 45/500\n",
            "25/25 [==============================] - 3s 132ms/step - loss: 0.7063 - sparse_categorical_accuracy: 0.7175 - val_loss: 0.8035 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 46/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6503 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.8594 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 47/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.7270 - sparse_categorical_accuracy: 0.7100 - val_loss: 0.7156 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 48/500\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.6755 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.7767 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 49/500\n",
            "25/25 [==============================] - 4s 159ms/step - loss: 0.7043 - sparse_categorical_accuracy: 0.7262 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 50/500\n",
            "25/25 [==============================] - 3s 120ms/step - loss: 0.6919 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.7342 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 51/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6800 - sparse_categorical_accuracy: 0.7538 - val_loss: 1.1631 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 52/500\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.6896 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.7707 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 53/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6795 - sparse_categorical_accuracy: 0.7225 - val_loss: 0.9428 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 54/500\n",
            "25/25 [==============================] - 3s 111ms/step - loss: 0.6792 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.9194 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 55/500\n",
            "25/25 [==============================] - 3s 136ms/step - loss: 0.7052 - sparse_categorical_accuracy: 0.7188 - val_loss: 1.2042 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 56/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.7150 - sparse_categorical_accuracy: 0.7163 - val_loss: 0.8202 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 57/500\n",
            "25/25 [==============================] - 3s 118ms/step - loss: 0.6779 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.7096 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 58/500\n",
            "25/25 [==============================] - 4s 162ms/step - loss: 0.7076 - sparse_categorical_accuracy: 0.7237 - val_loss: 0.9160 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 59/500\n",
            "25/25 [==============================] - 5s 185ms/step - loss: 0.6616 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.7175 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 60/500\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 0.6741 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.6266 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 61/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6984 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.6232 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 62/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6754 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 63/500\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.6770 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.6423 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 64/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6592 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.7550 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 65/500\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 0.6916 - sparse_categorical_accuracy: 0.7175 - val_loss: 0.6726 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 66/500\n",
            "25/25 [==============================] - 3s 120ms/step - loss: 0.7039 - sparse_categorical_accuracy: 0.7237 - val_loss: 0.6567 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 67/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.9799 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 68/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6668 - sparse_categorical_accuracy: 0.7262 - val_loss: 1.0587 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 69/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6684 - sparse_categorical_accuracy: 0.7287 - val_loss: 1.0844 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 70/500\n",
            "25/25 [==============================] - 4s 154ms/step - loss: 0.6983 - sparse_categorical_accuracy: 0.7275 - val_loss: 1.1210 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 71/500\n",
            "25/25 [==============================] - 4s 152ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.7337 - val_loss: 1.0718 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 72/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6992 - sparse_categorical_accuracy: 0.7262 - val_loss: 0.7152 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 73/500\n",
            "25/25 [==============================] - 2s 89ms/step - loss: 0.6828 - sparse_categorical_accuracy: 0.7138 - val_loss: 0.7440 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 74/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6679 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.6306 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 75/500\n",
            "25/25 [==============================] - 3s 116ms/step - loss: 0.6887 - sparse_categorical_accuracy: 0.7362 - val_loss: 1.0627 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 76/500\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.6630 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.9504 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 77/500\n",
            "25/25 [==============================] - 4s 150ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.7076 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 78/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6688 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.7804 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 79/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.7020 - sparse_categorical_accuracy: 0.7225 - val_loss: 1.0584 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 80/500\n",
            "25/25 [==============================] - 4s 146ms/step - loss: 0.6893 - sparse_categorical_accuracy: 0.7125 - val_loss: 1.2954 - val_sparse_categorical_accuracy: 0.5455\n",
            "Epoch 81/500\n",
            "25/25 [==============================] - 3s 133ms/step - loss: 0.6787 - sparse_categorical_accuracy: 0.7513 - val_loss: 1.2777 - val_sparse_categorical_accuracy: 0.5273\n",
            "Epoch 82/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6798 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 83/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6949 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.8827 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 84/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6785 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.9185 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 85/500\n",
            "25/25 [==============================] - 4s 147ms/step - loss: 0.6991 - sparse_categorical_accuracy: 0.7237 - val_loss: 0.7674 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 86/500\n",
            "25/25 [==============================] - 3s 129ms/step - loss: 0.6904 - sparse_categorical_accuracy: 0.7212 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 87/500\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.6526 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 88/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6748 - sparse_categorical_accuracy: 0.7350 - val_loss: 1.2304 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 89/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6835 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.8180 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 90/500\n",
            "25/25 [==============================] - 4s 160ms/step - loss: 0.7086 - sparse_categorical_accuracy: 0.7300 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 91/500\n",
            "25/25 [==============================] - 3s 129ms/step - loss: 0.6769 - sparse_categorical_accuracy: 0.7088 - val_loss: 0.7821 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 92/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6800 - sparse_categorical_accuracy: 0.7513 - val_loss: 1.0096 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 93/500\n",
            "25/25 [==============================] - 3s 133ms/step - loss: 0.6713 - sparse_categorical_accuracy: 0.7250 - val_loss: 1.1887 - val_sparse_categorical_accuracy: 0.5636\n",
            "Epoch 94/500\n",
            "25/25 [==============================] - 4s 166ms/step - loss: 0.7050 - sparse_categorical_accuracy: 0.7325 - val_loss: 1.0262 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 95/500\n",
            "25/25 [==============================] - 4s 153ms/step - loss: 0.6890 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.7453 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 96/500\n",
            "25/25 [==============================] - 3s 97ms/step - loss: 0.6683 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.7917 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 97/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.7055 - sparse_categorical_accuracy: 0.7312 - val_loss: 1.0485 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 98/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.7033 - sparse_categorical_accuracy: 0.7212 - val_loss: 1.1907 - val_sparse_categorical_accuracy: 0.5727\n",
            "Epoch 99/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6897 - sparse_categorical_accuracy: 0.7362 - val_loss: 1.1443 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 100/500\n",
            "25/25 [==============================] - 4s 145ms/step - loss: 0.6587 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.7164 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 101/500\n",
            "25/25 [==============================] - 4s 151ms/step - loss: 0.6644 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.7925 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 102/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6750 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.7749 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 103/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6930 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.5809 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 104/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6866 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 105/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6556 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.9779 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 106/500\n",
            "25/25 [==============================] - 4s 159ms/step - loss: 0.6511 - sparse_categorical_accuracy: 0.7437 - val_loss: 1.0887 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 107/500\n",
            "25/25 [==============================] - 3s 133ms/step - loss: 0.6720 - sparse_categorical_accuracy: 0.7337 - val_loss: 1.0930 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 108/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6824 - sparse_categorical_accuracy: 0.7250 - val_loss: 0.8761 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 109/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6373 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.9407 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 110/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6450 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.9026 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 111/500\n",
            "25/25 [==============================] - 4s 180ms/step - loss: 0.6633 - sparse_categorical_accuracy: 0.7475 - val_loss: 0.5988 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 112/500\n",
            "25/25 [==============================] - 5s 187ms/step - loss: 0.7165 - sparse_categorical_accuracy: 0.7025 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 113/500\n",
            "25/25 [==============================] - 4s 163ms/step - loss: 0.6673 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.9262 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 114/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6707 - sparse_categorical_accuracy: 0.7400 - val_loss: 1.0351 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 115/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6986 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.8746 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 116/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6645 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.9041 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 117/500\n",
            "25/25 [==============================] - 4s 155ms/step - loss: 0.6672 - sparse_categorical_accuracy: 0.7412 - val_loss: 1.0347 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 118/500\n",
            "25/25 [==============================] - 3s 124ms/step - loss: 0.6710 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.7529 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 119/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6664 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.9654 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 120/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6340 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.7986 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 121/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6752 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.8679 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 122/500\n",
            "25/25 [==============================] - 3s 112ms/step - loss: 0.6620 - sparse_categorical_accuracy: 0.7350 - val_loss: 1.0872 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 123/500\n",
            "25/25 [==============================] - 3s 136ms/step - loss: 0.6549 - sparse_categorical_accuracy: 0.7337 - val_loss: 1.3561 - val_sparse_categorical_accuracy: 0.5182\n",
            "Epoch 124/500\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.6511 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.9144 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 125/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6503 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.7205 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 126/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6362 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.8540 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 127/500\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.6648 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.9589 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 128/500\n",
            "25/25 [==============================] - 3s 137ms/step - loss: 0.6687 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.9027 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 129/500\n",
            "25/25 [==============================] - 3s 132ms/step - loss: 0.6794 - sparse_categorical_accuracy: 0.7287 - val_loss: 0.9686 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 130/500\n",
            "25/25 [==============================] - 4s 148ms/step - loss: 0.6663 - sparse_categorical_accuracy: 0.7462 - val_loss: 1.0729 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 131/500\n",
            "25/25 [==============================] - 4s 152ms/step - loss: 0.6543 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.9326 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 132/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6680 - sparse_categorical_accuracy: 0.7275 - val_loss: 0.8346 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 133/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6641 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8379 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 134/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6818 - sparse_categorical_accuracy: 0.7200 - val_loss: 0.7810 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 135/500\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.6923 - sparse_categorical_accuracy: 0.7287 - val_loss: 0.9550 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 136/500\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 0.6357 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.8877 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 137/500\n",
            "25/25 [==============================] - 3s 119ms/step - loss: 0.6674 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.7656 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 138/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6766 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.8127 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 139/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6706 - sparse_categorical_accuracy: 0.7362 - val_loss: 1.1320 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 140/500\n",
            "25/25 [==============================] - 3s 101ms/step - loss: 0.6626 - sparse_categorical_accuracy: 0.7237 - val_loss: 0.8926 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 141/500\n",
            "25/25 [==============================] - 4s 151ms/step - loss: 0.6600 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.7367 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 142/500\n",
            "25/25 [==============================] - 4s 152ms/step - loss: 0.6446 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.9227 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 143/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6517 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.7493 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 144/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6655 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.6541 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 145/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6478 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6957 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 146/500\n",
            "25/25 [==============================] - 3s 115ms/step - loss: 0.6762 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.8750 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 147/500\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.6638 - sparse_categorical_accuracy: 0.7300 - val_loss: 1.2996 - val_sparse_categorical_accuracy: 0.5636\n",
            "Epoch 148/500\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 0.6646 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.9674 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 149/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6630 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.9129 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 150/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6708 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.8219 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 151/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6653 - sparse_categorical_accuracy: 0.7500 - val_loss: 1.4945 - val_sparse_categorical_accuracy: 0.5091\n",
            "Epoch 152/500\n",
            "25/25 [==============================] - 4s 162ms/step - loss: 0.6469 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.9798 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 153/500\n",
            "25/25 [==============================] - 4s 145ms/step - loss: 0.6455 - sparse_categorical_accuracy: 0.7337 - val_loss: 1.0404 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 154/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6568 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8816 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 155/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6781 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 156/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6409 - sparse_categorical_accuracy: 0.7588 - val_loss: 1.0305 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 157/500\n",
            "25/25 [==============================] - 3s 127ms/step - loss: 0.6612 - sparse_categorical_accuracy: 0.7262 - val_loss: 1.0898 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 158/500\n",
            "25/25 [==============================] - 3s 137ms/step - loss: 0.6652 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.7740 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 159/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6600 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 160/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6814 - sparse_categorical_accuracy: 0.7225 - val_loss: 1.3133 - val_sparse_categorical_accuracy: 0.5364\n",
            "Epoch 161/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6560 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.8060 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 162/500\n",
            "25/25 [==============================] - 4s 153ms/step - loss: 0.6358 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.8028 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 163/500\n",
            "25/25 [==============================] - 3s 134ms/step - loss: 0.6968 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.8321 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 164/500\n",
            "25/25 [==============================] - 3s 126ms/step - loss: 0.6733 - sparse_categorical_accuracy: 0.7212 - val_loss: 0.7375 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 165/500\n",
            "25/25 [==============================] - 4s 155ms/step - loss: 0.6847 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.8905 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 166/500\n",
            "25/25 [==============================] - 4s 154ms/step - loss: 0.6760 - sparse_categorical_accuracy: 0.7450 - val_loss: 1.1799 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 167/500\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 0.6523 - sparse_categorical_accuracy: 0.7287 - val_loss: 0.8722 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 168/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6498 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8238 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 169/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6674 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 170/500\n",
            "25/25 [==============================] - 3s 137ms/step - loss: 0.6236 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.7874 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 171/500\n",
            "25/25 [==============================] - 3s 133ms/step - loss: 0.6681 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.9417 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 172/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6925 - sparse_categorical_accuracy: 0.7225 - val_loss: 0.6182 - val_sparse_categorical_accuracy: 0.8182\n",
            "Epoch 173/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6267 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.7524 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 174/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6380 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.8160 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 175/500\n",
            "25/25 [==============================] - 4s 151ms/step - loss: 0.6674 - sparse_categorical_accuracy: 0.7487 - val_loss: 1.0747 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 176/500\n",
            "25/25 [==============================] - 3s 131ms/step - loss: 0.6501 - sparse_categorical_accuracy: 0.7638 - val_loss: 0.7042 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 177/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6838 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.7269 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 178/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.7095 - sparse_categorical_accuracy: 0.7138 - val_loss: 0.8064 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 179/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6410 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.8391 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 180/500\n",
            "25/25 [==============================] - 4s 162ms/step - loss: 0.6583 - sparse_categorical_accuracy: 0.7300 - val_loss: 0.7465 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 181/500\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.6547 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.6390 - val_sparse_categorical_accuracy: 0.8000\n",
            "Epoch 182/500\n",
            "25/25 [==============================] - 4s 167ms/step - loss: 0.6440 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.8491 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 183/500\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6593 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.7507 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 184/500\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.6507 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.7658 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 185/500\n",
            "25/25 [==============================] - 3s 100ms/step - loss: 0.6184 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.7556 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 186/500\n",
            "25/25 [==============================] - 4s 160ms/step - loss: 0.6828 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.6354 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 187/500\n",
            "25/25 [==============================] - 3s 125ms/step - loss: 0.6488 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6028 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 188/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6237 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.8096 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 189/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6615 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.9725 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 190/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6433 - sparse_categorical_accuracy: 0.7475 - val_loss: 1.3783 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 191/500\n",
            "25/25 [==============================] - 3s 112ms/step - loss: 0.6818 - sparse_categorical_accuracy: 0.7225 - val_loss: 0.8654 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 192/500\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 0.6744 - sparse_categorical_accuracy: 0.7225 - val_loss: 0.6481 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 193/500\n",
            "25/25 [==============================] - 4s 140ms/step - loss: 0.6615 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.7243 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 194/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6683 - sparse_categorical_accuracy: 0.7275 - val_loss: 0.7625 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 195/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6613 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.6899 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 196/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6667 - sparse_categorical_accuracy: 0.7300 - val_loss: 0.7493 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 197/500\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 0.6682 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.8026 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 198/500\n",
            "25/25 [==============================] - 4s 153ms/step - loss: 0.6784 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.8353 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 199/500\n",
            "25/25 [==============================] - 3s 129ms/step - loss: 0.6397 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.7319 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 200/500\n",
            "25/25 [==============================] - 4s 153ms/step - loss: 0.6443 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.7828 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 201/500\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 0.6301 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6607 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 202/500\n",
            "25/25 [==============================] - 4s 153ms/step - loss: 0.6385 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.5805 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 203/500\n",
            "25/25 [==============================] - 6s 221ms/step - loss: 0.6177 - sparse_categorical_accuracy: 0.7663 - val_loss: 0.7649 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 204/500\n",
            "25/25 [==============================] - 3s 127ms/step - loss: 0.6829 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.7918 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 205/500\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.6779 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 206/500\n",
            "25/25 [==============================] - 4s 160ms/step - loss: 0.6399 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.6323 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 207/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6610 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.6728 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 208/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6519 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.9105 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 209/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6852 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 210/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6529 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.8456 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 211/500\n",
            "25/25 [==============================] - 4s 169ms/step - loss: 0.6775 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.8933 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 212/500\n",
            "25/25 [==============================] - 3s 133ms/step - loss: 0.6581 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.7726 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 213/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6863 - sparse_categorical_accuracy: 0.7212 - val_loss: 1.0957 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 214/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6751 - sparse_categorical_accuracy: 0.7212 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 215/500\n",
            "25/25 [==============================] - 3s 108ms/step - loss: 0.6488 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.7736 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 216/500\n",
            "25/25 [==============================] - 4s 172ms/step - loss: 0.6150 - sparse_categorical_accuracy: 0.7638 - val_loss: 0.6798 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 217/500\n",
            "25/25 [==============================] - 4s 172ms/step - loss: 0.6529 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.7714 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 218/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6351 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8086 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 219/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6801 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.6782 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 220/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6710 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.9325 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 221/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6480 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.7713 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 222/500\n",
            "25/25 [==============================] - 4s 159ms/step - loss: 0.6662 - sparse_categorical_accuracy: 0.7325 - val_loss: 0.6506 - val_sparse_categorical_accuracy: 0.8091\n",
            "Epoch 223/500\n",
            "25/25 [==============================] - 3s 134ms/step - loss: 0.6848 - sparse_categorical_accuracy: 0.7188 - val_loss: 0.7965 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 224/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6773 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.8332 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 225/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6645 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.6144 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 226/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.7039 - sparse_categorical_accuracy: 0.7287 - val_loss: 0.9038 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 227/500\n",
            "25/25 [==============================] - 3s 117ms/step - loss: 0.6707 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.9733 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 228/500\n",
            "25/25 [==============================] - 4s 143ms/step - loss: 0.6670 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.7958 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 229/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6551 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6744 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 230/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6528 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.7742 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 231/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6737 - sparse_categorical_accuracy: 0.7212 - val_loss: 1.1447 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 232/500\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6285 - sparse_categorical_accuracy: 0.7450 - val_loss: 1.1451 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 233/500\n",
            "25/25 [==============================] - 4s 164ms/step - loss: 0.6538 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.8533 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 234/500\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 0.6719 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.7660 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 235/500\n",
            "25/25 [==============================] - 3s 113ms/step - loss: 0.6578 - sparse_categorical_accuracy: 0.7287 - val_loss: 1.0298 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 236/500\n",
            "25/25 [==============================] - 3s 109ms/step - loss: 0.6655 - sparse_categorical_accuracy: 0.7287 - val_loss: 0.7732 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 237/500\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.6408 - sparse_categorical_accuracy: 0.7437 - val_loss: 1.2311 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 238/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6586 - sparse_categorical_accuracy: 0.7350 - val_loss: 1.1252 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 239/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6283 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.8165 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 240/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6516 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.8533 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 241/500\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6259 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.6840 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 242/500\n",
            "25/25 [==============================] - 4s 167ms/step - loss: 0.7008 - sparse_categorical_accuracy: 0.7237 - val_loss: 0.8017 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 243/500\n",
            "25/25 [==============================] - 3s 133ms/step - loss: 0.6620 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.7385 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 244/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6523 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.7177 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 245/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6531 - sparse_categorical_accuracy: 0.7487 - val_loss: 1.0248 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 246/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6396 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.6327 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 247/500\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 0.6454 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.7628 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 248/500\n",
            "25/25 [==============================] - 3s 135ms/step - loss: 0.6440 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.7878 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 249/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6531 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.7704 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 250/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6641 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.9460 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 251/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6760 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.7120 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 252/500\n",
            "25/25 [==============================] - 4s 180ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.8521 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 253/500\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.6467 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.7746 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 254/500\n",
            "25/25 [==============================] - 4s 167ms/step - loss: 0.6298 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.9404 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 255/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6588 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.9212 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 256/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6429 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.7328 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 257/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6744 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.9227 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 258/500\n",
            "25/25 [==============================] - 3s 107ms/step - loss: 0.6598 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 259/500\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.6817 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.8247 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 260/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6591 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8371 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 261/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.5993 - sparse_categorical_accuracy: 0.7700 - val_loss: 1.0445 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 262/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6254 - sparse_categorical_accuracy: 0.7638 - val_loss: 1.6767 - val_sparse_categorical_accuracy: 0.5000\n",
            "Epoch 263/500\n",
            "25/25 [==============================] - 4s 147ms/step - loss: 0.6359 - sparse_categorical_accuracy: 0.7675 - val_loss: 1.1765 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 264/500\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.6327 - sparse_categorical_accuracy: 0.7550 - val_loss: 1.0819 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 265/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6467 - sparse_categorical_accuracy: 0.7475 - val_loss: 0.8313 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 266/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6271 - sparse_categorical_accuracy: 0.7575 - val_loss: 1.0283 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 267/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6409 - sparse_categorical_accuracy: 0.7513 - val_loss: 1.0698 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 268/500\n",
            "25/25 [==============================] - 4s 156ms/step - loss: 0.6632 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.7234 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 269/500\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.6251 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.6565 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 270/500\n",
            "25/25 [==============================] - 4s 172ms/step - loss: 0.6443 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.9175 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 271/500\n",
            "25/25 [==============================] - 3s 102ms/step - loss: 0.6560 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.6893 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 272/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6591 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.8579 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 273/500\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 0.6614 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8499 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 274/500\n",
            "25/25 [==============================] - 4s 156ms/step - loss: 0.6727 - sparse_categorical_accuracy: 0.7237 - val_loss: 0.6899 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 275/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6286 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.6668 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 276/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6510 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.7640 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 277/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6441 - sparse_categorical_accuracy: 0.7475 - val_loss: 0.8253 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 278/500\n",
            "25/25 [==============================] - 3s 108ms/step - loss: 0.6597 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.7757 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 279/500\n",
            "25/25 [==============================] - 4s 144ms/step - loss: 0.6207 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.9280 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 280/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6524 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.8760 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 281/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6538 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.7568 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 282/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6283 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6622 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 283/500\n",
            "25/25 [==============================] - 3s 109ms/step - loss: 0.6540 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.8754 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 284/500\n",
            "25/25 [==============================] - 4s 145ms/step - loss: 0.6537 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.9221 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 285/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6404 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.7994 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 286/500\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.6566 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.7935 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 287/500\n",
            "25/25 [==============================] - 4s 163ms/step - loss: 0.6395 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.8549 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 288/500\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.6848 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8714 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 289/500\n",
            "25/25 [==============================] - 4s 150ms/step - loss: 0.6577 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.9382 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 290/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6236 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.8023 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 291/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6530 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.9491 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 292/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6227 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.7747 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 293/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6480 - sparse_categorical_accuracy: 0.7563 - val_loss: 0.6331 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 294/500\n",
            "25/25 [==============================] - 4s 161ms/step - loss: 0.6551 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.8571 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 295/500\n",
            "25/25 [==============================] - 3s 133ms/step - loss: 0.6292 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.7626 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 296/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6551 - sparse_categorical_accuracy: 0.7450 - val_loss: 1.2122 - val_sparse_categorical_accuracy: 0.6182\n",
            "Epoch 297/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6485 - sparse_categorical_accuracy: 0.7300 - val_loss: 0.7405 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 298/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6379 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.9114 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 299/500\n",
            "25/25 [==============================] - 3s 110ms/step - loss: 0.6222 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.6811 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 300/500\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 0.6314 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 301/500\n",
            "25/25 [==============================] - 3s 126ms/step - loss: 0.6357 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.6193 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 302/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6552 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.7987 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 303/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6371 - sparse_categorical_accuracy: 0.7638 - val_loss: 0.9444 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 304/500\n",
            "25/25 [==============================] - 3s 108ms/step - loss: 0.6516 - sparse_categorical_accuracy: 0.7487 - val_loss: 1.1457 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 305/500\n",
            "25/25 [==============================] - 4s 176ms/step - loss: 0.6361 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.8469 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 306/500\n",
            "25/25 [==============================] - 5s 187ms/step - loss: 0.6657 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.9940 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 307/500\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 0.6648 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.6353 - val_sparse_categorical_accuracy: 0.8000\n",
            "Epoch 308/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6598 - sparse_categorical_accuracy: 0.7475 - val_loss: 0.6571 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 309/500\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 0.6516 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8828 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 310/500\n",
            "25/25 [==============================] - 3s 94ms/step - loss: 0.6460 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.7442 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 311/500\n",
            "25/25 [==============================] - 4s 148ms/step - loss: 0.6471 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.6048 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 312/500\n",
            "25/25 [==============================] - 4s 140ms/step - loss: 0.6272 - sparse_categorical_accuracy: 0.7563 - val_loss: 0.5835 - val_sparse_categorical_accuracy: 0.8091\n",
            "Epoch 313/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6319 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.7359 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 314/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6084 - sparse_categorical_accuracy: 0.7563 - val_loss: 0.8703 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 315/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6215 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.7064 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 316/500\n",
            "25/25 [==============================] - 4s 160ms/step - loss: 0.6296 - sparse_categorical_accuracy: 0.7663 - val_loss: 1.1256 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 317/500\n",
            "25/25 [==============================] - 4s 156ms/step - loss: 0.6781 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.6148 - val_sparse_categorical_accuracy: 0.8000\n",
            "Epoch 318/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6819 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.7257 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 319/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6514 - sparse_categorical_accuracy: 0.7300 - val_loss: 0.6975 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 320/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6487 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.6948 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 321/500\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.6129 - sparse_categorical_accuracy: 0.7688 - val_loss: 0.6626 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 322/500\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 0.6616 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.7424 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 323/500\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.6600 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 324/500\n",
            "25/25 [==============================] - 4s 160ms/step - loss: 0.6429 - sparse_categorical_accuracy: 0.7563 - val_loss: 0.6800 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 325/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6246 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.9753 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 326/500\n",
            "25/25 [==============================] - 3s 134ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.6108 - val_sparse_categorical_accuracy: 0.8000\n",
            "Epoch 327/500\n",
            "25/25 [==============================] - 4s 153ms/step - loss: 0.6300 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.7154 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 328/500\n",
            "25/25 [==============================] - 3s 130ms/step - loss: 0.6074 - sparse_categorical_accuracy: 0.7688 - val_loss: 0.7051 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 329/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6427 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.7955 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 330/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6489 - sparse_categorical_accuracy: 0.7362 - val_loss: 1.2673 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 331/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6145 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6328 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 332/500\n",
            "25/25 [==============================] - 4s 163ms/step - loss: 0.6428 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 333/500\n",
            "25/25 [==============================] - 4s 161ms/step - loss: 0.6726 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.6069 - val_sparse_categorical_accuracy: 0.8091\n",
            "Epoch 334/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6344 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 335/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6294 - sparse_categorical_accuracy: 0.7613 - val_loss: 1.0052 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 336/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6352 - sparse_categorical_accuracy: 0.7475 - val_loss: 0.9532 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 337/500\n",
            "25/25 [==============================] - 3s 124ms/step - loss: 0.6312 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.7190 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 338/500\n",
            "25/25 [==============================] - 4s 163ms/step - loss: 0.6562 - sparse_categorical_accuracy: 0.7387 - val_loss: 1.0528 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 339/500\n",
            "25/25 [==============================] - 3s 114ms/step - loss: 0.6368 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 340/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6684 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.6293 - val_sparse_categorical_accuracy: 0.8000\n",
            "Epoch 341/500\n",
            "25/25 [==============================] - 4s 165ms/step - loss: 0.6243 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.8485 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 342/500\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.6385 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.8817 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 343/500\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.5899 - sparse_categorical_accuracy: 0.7713 - val_loss: 0.7178 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 344/500\n",
            "25/25 [==============================] - 3s 98ms/step - loss: 0.6116 - sparse_categorical_accuracy: 0.7713 - val_loss: 0.8668 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 345/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6630 - sparse_categorical_accuracy: 0.7275 - val_loss: 0.6975 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 346/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6440 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.9318 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 347/500\n",
            "25/25 [==============================] - 4s 156ms/step - loss: 0.6426 - sparse_categorical_accuracy: 0.7437 - val_loss: 1.0058 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 348/500\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.6843 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.6198 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 349/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6348 - sparse_categorical_accuracy: 0.7450 - val_loss: 1.0088 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 350/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6871 - sparse_categorical_accuracy: 0.7175 - val_loss: 0.8883 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 351/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6348 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.8379 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 352/500\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 0.6343 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.8942 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 353/500\n",
            "25/25 [==============================] - 4s 139ms/step - loss: 0.6115 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.6409 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 354/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6467 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.8020 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 355/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6371 - sparse_categorical_accuracy: 0.7588 - val_loss: 1.2572 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 356/500\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6431 - sparse_categorical_accuracy: 0.7738 - val_loss: 0.9768 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 357/500\n",
            "25/25 [==============================] - 4s 169ms/step - loss: 0.6137 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6627 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 358/500\n",
            "25/25 [==============================] - 5s 186ms/step - loss: 0.6824 - sparse_categorical_accuracy: 0.7188 - val_loss: 0.8109 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 359/500\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 0.6459 - sparse_categorical_accuracy: 0.7262 - val_loss: 0.9074 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 360/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6155 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.8269 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 361/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6208 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.8304 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 362/500\n",
            "25/25 [==============================] - 3s 131ms/step - loss: 0.6290 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.6514 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 363/500\n",
            "25/25 [==============================] - 4s 143ms/step - loss: 0.6343 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.6238 - val_sparse_categorical_accuracy: 0.8273\n",
            "Epoch 364/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6340 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.8937 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 365/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6396 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.6376 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 366/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6586 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.6399 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 367/500\n",
            "25/25 [==============================] - 4s 152ms/step - loss: 0.6518 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.7845 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 368/500\n",
            "25/25 [==============================] - 4s 139ms/step - loss: 0.6264 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.7116 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 369/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6414 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.6579 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 370/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6205 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.6902 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 371/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6225 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.6458 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 372/500\n",
            "25/25 [==============================] - 3s 121ms/step - loss: 0.6453 - sparse_categorical_accuracy: 0.7725 - val_loss: 0.7886 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 373/500\n",
            "25/25 [==============================] - 4s 145ms/step - loss: 0.6568 - sparse_categorical_accuracy: 0.7312 - val_loss: 1.0657 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 374/500\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.6310 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.7396 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 375/500\n",
            "25/25 [==============================] - 4s 146ms/step - loss: 0.6601 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.7610 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 376/500\n",
            "25/25 [==============================] - 5s 178ms/step - loss: 0.6368 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8963 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 377/500\n",
            "25/25 [==============================] - 4s 172ms/step - loss: 0.5945 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.7865 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 378/500\n",
            "25/25 [==============================] - 3s 136ms/step - loss: 0.6375 - sparse_categorical_accuracy: 0.7387 - val_loss: 1.1013 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 379/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.5876 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.7386 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 380/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6507 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.6642 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 381/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6497 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6615 - val_sparse_categorical_accuracy: 0.8000\n",
            "Epoch 382/500\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 0.6484 - sparse_categorical_accuracy: 0.7475 - val_loss: 0.8605 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 383/500\n",
            "25/25 [==============================] - 3s 136ms/step - loss: 0.6146 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 384/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6587 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.7260 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 385/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6435 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.8342 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 386/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6285 - sparse_categorical_accuracy: 0.7475 - val_loss: 0.7264 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 387/500\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 0.6246 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.7078 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 388/500\n",
            "25/25 [==============================] - 3s 137ms/step - loss: 0.6523 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.9267 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 389/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6488 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.8508 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 390/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6327 - sparse_categorical_accuracy: 0.7638 - val_loss: 0.8016 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 391/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6306 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.7152 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 392/500\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 0.6000 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.7850 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 393/500\n",
            "25/25 [==============================] - 4s 178ms/step - loss: 0.6291 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.6419 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 394/500\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.6157 - sparse_categorical_accuracy: 0.7750 - val_loss: 0.6058 - val_sparse_categorical_accuracy: 0.8091\n",
            "Epoch 395/500\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 0.6356 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.6793 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 396/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.5926 - sparse_categorical_accuracy: 0.7738 - val_loss: 0.6532 - val_sparse_categorical_accuracy: 0.8091\n",
            "Epoch 397/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6386 - sparse_categorical_accuracy: 0.7563 - val_loss: 0.8757 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 398/500\n",
            "25/25 [==============================] - 3s 101ms/step - loss: 0.6211 - sparse_categorical_accuracy: 0.7563 - val_loss: 0.7294 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 399/500\n",
            "25/25 [==============================] - 4s 151ms/step - loss: 0.6881 - sparse_categorical_accuracy: 0.7250 - val_loss: 0.7310 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 400/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6577 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.7305 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 401/500\n",
            "25/25 [==============================] - 3s 100ms/step - loss: 0.6384 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.6492 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 402/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6242 - sparse_categorical_accuracy: 0.7663 - val_loss: 0.8151 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 403/500\n",
            "25/25 [==============================] - 3s 110ms/step - loss: 0.6278 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.8498 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 404/500\n",
            "25/25 [==============================] - 4s 162ms/step - loss: 0.6330 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.6216 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 405/500\n",
            "25/25 [==============================] - 4s 154ms/step - loss: 0.6436 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.6189 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 406/500\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.6294 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.6753 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 407/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6324 - sparse_categorical_accuracy: 0.7563 - val_loss: 1.0111 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 408/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6690 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.7286 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 409/500\n",
            "25/25 [==============================] - 3s 135ms/step - loss: 0.6188 - sparse_categorical_accuracy: 0.7700 - val_loss: 1.0909 - val_sparse_categorical_accuracy: 0.5818\n",
            "Epoch 410/500\n",
            "25/25 [==============================] - 4s 145ms/step - loss: 0.6243 - sparse_categorical_accuracy: 0.7688 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 411/500\n",
            "25/25 [==============================] - 3s 109ms/step - loss: 0.6457 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.9051 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 412/500\n",
            "25/25 [==============================] - 4s 143ms/step - loss: 0.6461 - sparse_categorical_accuracy: 0.7638 - val_loss: 0.7561 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 413/500\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.6401 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.6973 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 414/500\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.6521 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.8060 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 415/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6705 - sparse_categorical_accuracy: 0.7538 - val_loss: 1.1044 - val_sparse_categorical_accuracy: 0.6000\n",
            "Epoch 416/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6326 - sparse_categorical_accuracy: 0.7250 - val_loss: 0.9535 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 417/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6334 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8224 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 418/500\n",
            "25/25 [==============================] - 3s 106ms/step - loss: 0.6535 - sparse_categorical_accuracy: 0.7300 - val_loss: 0.9161 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 419/500\n",
            "25/25 [==============================] - 4s 147ms/step - loss: 0.6290 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.8141 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 420/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6202 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.9870 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 421/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6343 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.6180 - val_sparse_categorical_accuracy: 0.8182\n",
            "Epoch 422/500\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6174 - sparse_categorical_accuracy: 0.7563 - val_loss: 1.0105 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 423/500\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 0.6407 - sparse_categorical_accuracy: 0.7600 - val_loss: 1.4737 - val_sparse_categorical_accuracy: 0.5273\n",
            "Epoch 424/500\n",
            "25/25 [==============================] - 4s 147ms/step - loss: 0.6706 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.7566 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 425/500\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.6276 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.8545 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 426/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6413 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 427/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6276 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.7867 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 428/500\n",
            "25/25 [==============================] - 3s 140ms/step - loss: 0.5877 - sparse_categorical_accuracy: 0.7750 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.8000\n",
            "Epoch 429/500\n",
            "25/25 [==============================] - 5s 187ms/step - loss: 0.6165 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.8318 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 430/500\n",
            "25/25 [==============================] - 4s 156ms/step - loss: 0.6180 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.6493 - val_sparse_categorical_accuracy: 0.8000\n",
            "Epoch 431/500\n",
            "25/25 [==============================] - 3s 126ms/step - loss: 0.6247 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 432/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6391 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.8391 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 433/500\n",
            "25/25 [==============================] - 3s 140ms/step - loss: 0.6078 - sparse_categorical_accuracy: 0.7812 - val_loss: 0.7183 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 434/500\n",
            "25/25 [==============================] - 4s 145ms/step - loss: 0.6094 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.7803 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 435/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6246 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.9161 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 436/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6210 - sparse_categorical_accuracy: 0.7663 - val_loss: 0.6642 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 437/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6549 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.7975 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 438/500\n",
            "25/25 [==============================] - 3s 113ms/step - loss: 0.6322 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.8144 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 439/500\n",
            "25/25 [==============================] - 4s 162ms/step - loss: 0.6402 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6763 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 440/500\n",
            "25/25 [==============================] - 3s 123ms/step - loss: 0.6222 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.6778 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 441/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6234 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 442/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6230 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 443/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6623 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.6328 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 444/500\n",
            "25/25 [==============================] - 3s 129ms/step - loss: 0.6301 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.8698 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 445/500\n",
            "25/25 [==============================] - 4s 148ms/step - loss: 0.6532 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8327 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 446/500\n",
            "25/25 [==============================] - 3s 100ms/step - loss: 0.6281 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.7878 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 447/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6404 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.6528 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 448/500\n",
            "25/25 [==============================] - 4s 145ms/step - loss: 0.6745 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 449/500\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.6969 - sparse_categorical_accuracy: 0.7262 - val_loss: 0.7659 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 450/500\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.6293 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.6410 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 451/500\n",
            "25/25 [==============================] - 3s 136ms/step - loss: 0.6286 - sparse_categorical_accuracy: 0.7638 - val_loss: 0.7434 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 452/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6556 - sparse_categorical_accuracy: 0.7400 - val_loss: 1.0055 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 453/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6229 - sparse_categorical_accuracy: 0.7525 - val_loss: 1.0080 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 454/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6373 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.7490 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 455/500\n",
            "25/25 [==============================] - 4s 166ms/step - loss: 0.6039 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.8478 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 456/500\n",
            "25/25 [==============================] - 3s 136ms/step - loss: 0.5875 - sparse_categorical_accuracy: 0.7738 - val_loss: 0.6719 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 457/500\n",
            "25/25 [==============================] - 2s 97ms/step - loss: 0.6474 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.8557 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 458/500\n",
            "25/25 [==============================] - 3s 99ms/step - loss: 0.6294 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.7901 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 459/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6192 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.6983 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 460/500\n",
            "25/25 [==============================] - 3s 114ms/step - loss: 0.6290 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.8010 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 461/500\n",
            "25/25 [==============================] - 4s 154ms/step - loss: 0.6332 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.8148 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 462/500\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.6004 - sparse_categorical_accuracy: 0.7663 - val_loss: 0.7628 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 463/500\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.6062 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.8411 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 464/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6608 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.8751 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 465/500\n",
            "25/25 [==============================] - 3s 138ms/step - loss: 0.6218 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.7095 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 466/500\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.6286 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.9903 - val_sparse_categorical_accuracy: 0.6364\n",
            "Epoch 467/500\n",
            "25/25 [==============================] - 4s 163ms/step - loss: 0.6202 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6551 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 468/500\n",
            "25/25 [==============================] - 3s 102ms/step - loss: 0.6536 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.7657 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 469/500\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 0.6256 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.7571 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 470/500\n",
            "25/25 [==============================] - 4s 142ms/step - loss: 0.6435 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.9208 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 471/500\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.6103 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.8958 - val_sparse_categorical_accuracy: 0.6818\n",
            "Epoch 472/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.5909 - sparse_categorical_accuracy: 0.7725 - val_loss: 0.8393 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 473/500\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.6173 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.8886 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 474/500\n",
            "25/25 [==============================] - 4s 153ms/step - loss: 0.6244 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.6528 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 475/500\n",
            "25/25 [==============================] - 4s 155ms/step - loss: 0.6661 - sparse_categorical_accuracy: 0.7462 - val_loss: 1.1301 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 476/500\n",
            "25/25 [==============================] - 3s 117ms/step - loss: 0.6415 - sparse_categorical_accuracy: 0.7563 - val_loss: 1.0013 - val_sparse_categorical_accuracy: 0.6455\n",
            "Epoch 477/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6417 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.8191 - val_sparse_categorical_accuracy: 0.7091\n",
            "Epoch 478/500\n",
            "25/25 [==============================] - 2s 100ms/step - loss: 0.6144 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.6318 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 479/500\n",
            "25/25 [==============================] - 3s 128ms/step - loss: 0.6083 - sparse_categorical_accuracy: 0.7713 - val_loss: 0.6627 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 480/500\n",
            "25/25 [==============================] - 4s 163ms/step - loss: 0.6412 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.7556 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 481/500\n",
            "25/25 [==============================] - 4s 140ms/step - loss: 0.6063 - sparse_categorical_accuracy: 0.7812 - val_loss: 0.6845 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 482/500\n",
            "25/25 [==============================] - 2s 98ms/step - loss: 0.6454 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.6106 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 483/500\n",
            "25/25 [==============================] - 4s 153ms/step - loss: 0.6716 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.7764 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 484/500\n",
            "25/25 [==============================] - 4s 172ms/step - loss: 0.5917 - sparse_categorical_accuracy: 0.7625 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 485/500\n",
            "25/25 [==============================] - 4s 162ms/step - loss: 0.6443 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.6397 - val_sparse_categorical_accuracy: 0.7818\n",
            "Epoch 486/500\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.6253 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 487/500\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.6395 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.8252 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 488/500\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.6222 - sparse_categorical_accuracy: 0.7563 - val_loss: 0.6678 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 489/500\n",
            "25/25 [==============================] - 3s 103ms/step - loss: 0.6507 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.8334 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 490/500\n",
            "25/25 [==============================] - 4s 166ms/step - loss: 0.5884 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.7408 - val_sparse_categorical_accuracy: 0.7909\n",
            "Epoch 491/500\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 0.6224 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.8975 - val_sparse_categorical_accuracy: 0.6909\n",
            "Epoch 492/500\n",
            "25/25 [==============================] - 3s 100ms/step - loss: 0.5962 - sparse_categorical_accuracy: 0.7775 - val_loss: 0.8847 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 493/500\n",
            "25/25 [==============================] - 3s 100ms/step - loss: 0.6060 - sparse_categorical_accuracy: 0.7650 - val_loss: 1.4534 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 494/500\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.6171 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.8931 - val_sparse_categorical_accuracy: 0.7182\n",
            "Epoch 495/500\n",
            "25/25 [==============================] - 3s 121ms/step - loss: 0.6299 - sparse_categorical_accuracy: 0.7525 - val_loss: 1.0973 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 496/500\n",
            "25/25 [==============================] - 4s 151ms/step - loss: 0.6399 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.8606 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 497/500\n",
            "25/25 [==============================] - 2s 100ms/step - loss: 0.6267 - sparse_categorical_accuracy: 0.7625 - val_loss: 1.0446 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 498/500\n",
            "25/25 [==============================] - 3s 100ms/step - loss: 0.6188 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.7063 - val_sparse_categorical_accuracy: 0.7727\n",
            "Epoch 499/500\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.6467 - sparse_categorical_accuracy: 0.7513 - val_loss: 1.1918 - val_sparse_categorical_accuracy: 0.5909\n",
            "Epoch 500/500\n",
            "25/25 [==============================] - 4s 143ms/step - loss: 0.6091 - sparse_categorical_accuracy: 0.7725 - val_loss: 1.0069 - val_sparse_categorical_accuracy: 0.6545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4f2YbVV3SQp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EAp0Bvviz1t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OCrwLmP5z1wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert from tensorflow to tensorflow lite"
      ],
      "metadata": {
        "id": "oCwvSMSSl3D-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0yrGx2TniiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen=ImageDataGenerator(#rescale=1./255,\n",
        "                                 rotation_range=10,\n",
        "                                 width_shift_range=0.1,\n",
        "                                 height_shift_range=0.1,\n",
        "                                 horizontal_flip=True,\n",
        "                                 fill_mode='nearest')\n",
        "generator=datagen.flow_from_directory(val_data_dir,\n",
        "                                      target_size=IMAGE_SHAPE,\n",
        "                                      batch_size=BATCH_SIZE,\n",
        "                                      color_mode=\"grayscale\",\n",
        "                                      class_mode='sparse')\n",
        "def representative_data_gen():\n",
        "  i = 0\n",
        "  for image_batch, labels_batch in generator:\n",
        "    i = i+1\n",
        "    if i > 20:\n",
        "      break;\n",
        "    yield [image_batch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WZbO7ZJnIG4",
        "outputId": "e10ae431-58e2-454e-eeae-e35c0a70e95a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 110 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "print('\\nSetting the optimization flags..')\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "print('\\nConverting..')\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"person_detect_model_data.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "print(\"Done Conversion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4mbUSpQfiz5",
        "outputId": "fb06bf6f-b6e1-4071-8126-2e7885891896"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Setting the optimization flags..\n",
            "\n",
            "Converting..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  warnings.warn('Custom mask layers require a config and must override '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Conversion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert from tensorflow to c array"
      ],
      "metadata": {
        "id": "LsNCFAg-l789"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!xxd -i ./person_detect_model_data.tflite > person_detect_model_data.cpp"
      ],
      "metadata": {
        "id": "3lz68gN6rR9o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp /content/person_detect_model_data.cpp /content/person_detect_model_data_copy.cpp"
      ],
      "metadata": {
        "id": "R3DWOMYT0Ymj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "search_text1 = \"unsigned char __person_detect_model_data_tflite[]\"\n",
        "\n",
        "\n",
        "replace_text1 = str('#include \"person_detect_model_data.h\" \\n\\\n",
        "#ifdef __has_attribute \\n\\\n",
        "#define HAVE_ATTRIBUTE(x) __has_attribute(x) \\n\\\n",
        "#else \\n\\\n",
        "#define HAVE_ATTRIBUTE(x) 0 \\n\\\n",
        "#endif \\n\\\n",
        "#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__)) \\n\\\n",
        "#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4))) \\n\\\n",
        "#else \\n\\\n",
        "#define DATA_ALIGN_ATTRIBUTE \\n\\\n",
        "#endif \\n\\\n",
        "const unsigned char g_person_detect_model_data[] DATA_ALIGN_ATTRIBUTE')\n",
        "\n",
        "\n",
        "search_text2 = \"unsigned int __person_detect_model_data_tflite_len\"\n",
        "\n",
        "replace_text2 = \"const int g_person_detect_model_data_len\"\n",
        "\n",
        "with open(r'/content/person_detect_model_data.cpp', 'r') as file:\n",
        "\n",
        "    data = file.read()\n",
        "\n",
        "    data = data.replace(search_text1, replace_text1)\n",
        "    data = data.replace(search_text2, replace_text2)\n",
        "  # data = data.replace(search_text2, replace_text2)\n",
        "\n",
        "with open(r'/content/person_detect_model_data.cpp', 'w') as file:\n",
        "    file.write(data)\n",
        "    file.close()\n",
        "\n",
        "\n",
        "\n",
        "print(\"Text replaced\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDErADgkrnec",
        "outputId": "3d01a37b-ddfa-4130-c60b-0cbc30c5e3b6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text replaced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6jBeDVz8tLF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}